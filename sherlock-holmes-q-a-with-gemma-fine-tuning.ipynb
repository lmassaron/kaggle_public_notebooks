{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00095460",
   "metadata": {
    "papermill": {
     "duration": 0.014484,
     "end_time": "2024-04-14T22:14:04.002835",
     "exception": false,
     "start_time": "2024-04-14T22:14:03.988351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sherlock Holmes Q&A Enhanced with Gemma 2b-it Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155eaf7a",
   "metadata": {
    "papermill": {
     "duration": 0.013838,
     "end_time": "2024-04-14T22:14:04.030900",
     "exception": false,
     "start_time": "2024-04-14T22:14:04.017062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you want an LLM to answer a question about a topic on which it has not been trained, an alternative to building a RAG is to fine-tune a model to specifically answer a Q&A on that topic. \n",
    "\n",
    "In this Kaggle Notebook tutorial, I use Gemma 2b-it and Hugging Face packages to build a specialized Gemma model for answering tricky questions about Sherlock Holmes!\n",
    "\n",
    "In the tutorial, the steps shown are:\n",
    "\n",
    "1. retrieving a knowledge base from Wikipedia (but you can use any text you want)\n",
    "2. leveraging Gemma to build meaningful Q&A based on the knowledge base\n",
    "3. train Gemma on the Q&A data using 4-bit quantization and LoRA\n",
    "4. save the trained LoRA weights and merge them back into Gemma\n",
    "\n",
    "In the end, given some patience in gathering enough data and processing it in a Q&A form, you will have a very specialized Gemma model on the topic you want (not necessarily Sherlock Holmes)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6095d",
   "metadata": {
    "papermill": {
     "duration": 0.014656,
     "end_time": "2024-04-14T22:14:04.059502",
     "exception": false,
     "start_time": "2024-04-14T22:14:04.044846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![sherlock](https://th.bing.com/th/id/OIG4.rZxoJFLE5dJGsfn5F_hq?pid=ImgGn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812715c6",
   "metadata": {
    "papermill": {
     "duration": 0.013802,
     "end_time": "2024-04-14T22:14:04.087180",
     "exception": false,
     "start_time": "2024-04-14T22:14:04.073378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start on the Kaggle notebook with code that installs several Python packages using pip:\n",
    "\n",
    "* This first line installs the PyTorch library, which is used for deep learning tasks, particularly neural networks. The—q flag quiets the installation process (no output except for errors), and -U ensures that if PyTorch is installed, it will be updated to the latest version. The—index-url flag specifies a custom URL for package indexes. In this case, it’s downloading the PyTorch wheel from a specific URL for CUDA 11.7.\n",
    "* The following line installs a package named bitsandbytes from the Python Package Index (PyPI). Similar to the previous line, -q makes the installation quiet, -U updates the package if it’s already installed, and -i specifies the package index URL.\n",
    "* Next, it installs the transformers library, which provides state-of-the-art natural language processing models like BERT, GPT, etc. The flags -q and -U have the same meaning as before.\n",
    "* The following line installs the accelerate library, which provides utilities for high-performance computing, particularly in the context of deep learning. Again, -q and -U are used for quiet installation and updating the package.\n",
    "* The following line installs the datasets library, which provides easy access to various datasets for machine learning tasks. Once more, -q and -U are used for quiet installation and updating.\n",
    "* The following line installs the trl library, a full-stack library by HuggingFace that provides a set of tools to train transformer language models with Reinforcement Learning from the Supervised Fine-tuning step (SFT), Reward Modeling step (RM) to the Proximal Policy Optimization (PPO) step. As before,—q and -U are used for quiet installation and updating.\n",
    "* The following line installs the peft library, which is a Python library by HuggingFace for efficient adaptation of pre-trained language models (PLMs) to various downstream applications without fine-tuning all the model’s parameters. PEFT methods only fine-tune a small number of (extra) model parameters, thereby significantly decreasing the computational and storage costs.\n",
    "* Finally, the last line installs the wikipedia-api library, which provides an easy interface to interact with Wikipedia data. -q and -U are used for quiet installation and updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccba5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:14:04.116425Z",
     "iopub.status.busy": "2024-04-14T22:14:04.116068Z",
     "iopub.status.idle": "2024-04-14T22:15:51.693196Z",
     "shell.execute_reply": "2024-04-14T22:15:51.692143Z"
    },
    "papermill": {
     "duration": 107.59463,
     "end_time": "2024-04-14T22:15:51.695729",
     "exception": false,
     "start_time": "2024-04-14T22:14:04.101099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "!pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U transformers\n",
    "!pip install -q -U accelerate\n",
    "!pip install -q -U datasets\n",
    "!pip install -q -U trl\n",
    "!pip install -q -U peft\n",
    "!pip install -q -U wikipedia-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4c37f",
   "metadata": {
    "papermill": {
     "duration": 0.013557,
     "end_time": "2024-04-14T22:15:51.723973",
     "exception": false,
     "start_time": "2024-04-14T22:15:51.710416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code imports the os module and sets two environment variables:\n",
    "\n",
    "* CUDA_VISIBLE_DEVICES: This environment variable tells PyTorch which GPUs to use. In this case, the code sets the environment variable to 0, meaning that PyTorch will use the first GPU.\n",
    "\n",
    "* TOKENIZERS_PARALLELISM: This environment variable tells the Hugging Face Transformers library whether to parallelize the tokenization process. In this case, the code sets the environment variable to false, meaning the tokenization process will not be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdee3e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:15:51.753076Z",
     "iopub.status.busy": "2024-04-14T22:15:51.752746Z",
     "iopub.status.idle": "2024-04-14T22:15:51.757364Z",
     "shell.execute_reply": "2024-04-14T22:15:51.756515Z"
    },
    "papermill": {
     "duration": 0.021242,
     "end_time": "2024-04-14T22:15:51.759201",
     "exception": false,
     "start_time": "2024-04-14T22:15:51.737959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ea3a4",
   "metadata": {
    "papermill": {
     "duration": 0.014097,
     "end_time": "2024-04-14T22:15:51.787093",
     "exception": false,
     "start_time": "2024-04-14T22:15:51.772996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The code import warnings; warnings.filterwarnings(“ignore”) imports the warnings module and sets the warning filter to ignore. This means that all warnings will be suppressed and not displayed. During training, many warnings do not prevent fine-tuning but can be distracting and make you wonder if you are doing the correct thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe84ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:15:51.816197Z",
     "iopub.status.busy": "2024-04-14T22:15:51.815873Z",
     "iopub.status.idle": "2024-04-14T22:15:51.819923Z",
     "shell.execute_reply": "2024-04-14T22:15:51.819111Z"
    },
    "papermill": {
     "duration": 0.020847,
     "end_time": "2024-04-14T22:15:51.821835",
     "exception": false,
     "start_time": "2024-04-14T22:15:51.800988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22884875",
   "metadata": {
    "papermill": {
     "duration": 0.013665,
     "end_time": "2024-04-14T22:15:51.849301",
     "exception": false,
     "start_time": "2024-04-14T22:15:51.835636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the following cell, there are all the other imports for running the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e12364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:15:51.878932Z",
     "iopub.status.busy": "2024-04-14T22:15:51.878091Z",
     "iopub.status.idle": "2024-04-14T22:16:10.194139Z",
     "shell.execute_reply": "2024-04-14T22:16:10.193346Z"
    },
    "papermill": {
     "duration": 18.333346,
     "end_time": "2024-04-14T22:16:10.196424",
     "exception": false,
     "start_time": "2024-04-14T22:15:51.863078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:16:02.425722: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-14 22:16:02.425861: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-14 22:16:02.541792: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import wikipediaapi\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments,\n",
    "                          )\n",
    "\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cceb18",
   "metadata": {
    "papermill": {
     "duration": 0.013792,
     "end_time": "2024-04-14T22:16:10.224457",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.210665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The next cell presents a function that returns the device where to map the model and the data when working with the PyTorch library (used by the HF packages). It works with a CPU-based computer, a GPU one, and with a macOS with MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c27197eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:16:10.254451Z",
     "iopub.status.busy": "2024-04-14T22:16:10.253798Z",
     "iopub.status.idle": "2024-04-14T22:16:10.260710Z",
     "shell.execute_reply": "2024-04-14T22:16:10.259887Z"
    },
    "papermill": {
     "duration": 0.024224,
     "end_time": "2024-04-14T22:16:10.262656",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.238432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_device():\n",
    "    \"\"\"Define the device to be used by PyTorch\"\"\"\n",
    "\n",
    "    # Get the PyTorch version\n",
    "    torch_version = torch.__version__\n",
    "\n",
    "    # Print the PyTorch version\n",
    "    print(f\"PyTorch version: {torch_version}\", end=\" -- \")\n",
    "\n",
    "    # Check if MPS (Multi-Process Service) device is available on MacOS\n",
    "    if torch.backends.mps.is_available():\n",
    "        # If MPS is available, print a message indicating its usage\n",
    "        print(\"using MPS device on MacOS\")\n",
    "        # Define the device as MPS\n",
    "        defined_device = torch.device(\"mps\")\n",
    "    else:\n",
    "        # If MPS is not available, determine the device based on GPU availability\n",
    "        defined_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Print a message indicating the selected device\n",
    "        print(f\"using {defined_device}\")\n",
    "\n",
    "    # Return the defined device\n",
    "    return defined_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740618b",
   "metadata": {
    "papermill": {
     "duration": 0.013671,
     "end_time": "2024-04-14T22:16:10.290156",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.276485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1: get the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a29d6",
   "metadata": {
    "papermill": {
     "duration": 0.013386,
     "end_time": "2024-04-14T22:16:10.317271",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.303885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Apart from the first two functions helpful in cleaning the text from tags and formatting, the following code extracts references, such as pages or other Wikipedia categories, using the extract_wikipedia_pages function. Then, the get_wikipedia_pages function crawls to all the pages and information related to some initial Wikipedia category or page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fc57de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:16:10.346287Z",
     "iopub.status.busy": "2024-04-14T22:16:10.345428Z",
     "iopub.status.idle": "2024-04-14T22:16:10.351888Z",
     "shell.execute_reply": "2024-04-14T22:16:10.350996Z"
    },
    "papermill": {
     "duration": 0.022961,
     "end_time": "2024-04-14T22:16:10.353765",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.330804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-compile the regular expression pattern for better performance\n",
    "BRACES_PATTERN = re.compile(r'\\{.*?\\}|\\}')\n",
    "\n",
    "def remove_braces_and_content(text):\n",
    "    \"\"\"Remove all occurrences of curly braces and their content from the given text\"\"\"\n",
    "    return BRACES_PATTERN.sub('', text)\n",
    "\n",
    "def clean_string(input_string):\n",
    "    \"\"\"Clean the input string.\"\"\"\n",
    "    \n",
    "    # Remove extra spaces by splitting the string by spaces and joining back together\n",
    "    cleaned_string = ' '.join(input_string.split())\n",
    "    \n",
    "    # Remove consecutive carriage return characters until there are no more consecutive occurrences\n",
    "    cleaned_string = re.sub(r'\\r+', '\\r', cleaned_string)\n",
    "    \n",
    "    # Remove all occurrences of curly braces and their content from the cleaned string\n",
    "    cleaned_string = remove_braces_and_content(cleaned_string)\n",
    "    \n",
    "    # Return the cleaned string\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05aa07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:16:10.382973Z",
     "iopub.status.busy": "2024-04-14T22:16:10.382350Z",
     "iopub.status.idle": "2024-04-14T22:16:10.395236Z",
     "shell.execute_reply": "2024-04-14T22:16:10.394354Z"
    },
    "papermill": {
     "duration": 0.029628,
     "end_time": "2024-04-14T22:16:10.397089",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.367461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_wikipedia_pages(categories):\n",
    "    \"\"\"Retrieve Wikipedia pages from a list of categories and extract their content\"\"\"\n",
    "    \n",
    "    # Create a Wikipedia object\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('Gemma AI Assistant (gemma@example.com)', 'en')\n",
    "    \n",
    "    # Initialize lists to store explored categories and Wikipedia pages\n",
    "    explored_categories = []\n",
    "    wikipedia_pages = []\n",
    "\n",
    "    # Iterate through each category\n",
    "    print(\"- Processing Wikipedia categories:\")\n",
    "    for category_name in categories:\n",
    "        print(f\"\\tExploring {category_name} on Wikipedia\")\n",
    "        \n",
    "        # Get the Wikipedia page corresponding to the category\n",
    "        category = wiki_wiki.page(\"Category:\" + category_name)\n",
    "        \n",
    "        # Extract Wikipedia pages from the category and extend the list\n",
    "        wikipedia_pages.extend(extract_wikipedia_pages(wiki_wiki, category_name))\n",
    "        \n",
    "        # Add the explored category to the list\n",
    "        explored_categories.append(category_name)\n",
    "\n",
    "    # Extract subcategories and remove duplicate categories\n",
    "    categories_to_explore = [item.replace(\"Category:\", \"\") for item in wikipedia_pages if \"Category:\" in item]\n",
    "    wikipedia_pages = list(set([item for item in wikipedia_pages if \"Category:\" not in item]))\n",
    "    \n",
    "    # Explore subcategories recursively\n",
    "    while categories_to_explore:\n",
    "        category_name = categories_to_explore.pop()\n",
    "        print(f\"\\tExploring {category_name} on Wikipedia\")\n",
    "        \n",
    "        # Extract more references from the subcategory\n",
    "        more_refs = extract_wikipedia_pages(wiki_wiki, category_name)\n",
    "\n",
    "        # Iterate through the references\n",
    "        for ref in more_refs:\n",
    "            # Check if the reference is a category\n",
    "            if \"Category:\" in ref:\n",
    "                new_category = ref.replace(\"Category:\", \"\")\n",
    "                # Add the new category to the explored categories list\n",
    "                if new_category not in explored_categories:\n",
    "                    explored_categories.append(new_category)\n",
    "            else:\n",
    "                # Add the reference to the Wikipedia pages list\n",
    "                if ref not in wikipedia_pages:\n",
    "                    wikipedia_pages.append(ref)\n",
    "\n",
    "    # Initialize a list to store extracted texts\n",
    "    extracted_texts = []\n",
    "    \n",
    "    # Iterate through each Wikipedia page\n",
    "    print(\"- Processing Wikipedia pages:\")\n",
    "    for page_title in tqdm(wikipedia_pages):\n",
    "        try:\n",
    "            # Make a request to the Wikipedia page\n",
    "            page = wiki_wiki.page(page_title)\n",
    "\n",
    "            # Check if the page summary does not contain certain keywords\n",
    "            if \"Biden\" not in page.summary and \"Trump\" not in page.summary:\n",
    "                # Append the page title and summary to the extracted texts list\n",
    "                if len(page.summary) > len(page.title):\n",
    "                    extracted_texts.append(page.title + \" : \" + clean_string(page.summary))\n",
    "\n",
    "                # Iterate through the sections in the page\n",
    "                for section in page.sections:\n",
    "                    # Append the page title and section text to the extracted texts list\n",
    "                    if len(section.text) > len(page.title):\n",
    "                        extracted_texts.append(page.title + \" : \" + clean_string(section.text))\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {page.title}: {e}\")\n",
    "                    \n",
    "    # Return the extracted texts\n",
    "    return extracted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdfa373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:16:10.427303Z",
     "iopub.status.busy": "2024-04-14T22:16:10.426730Z",
     "iopub.status.idle": "2024-04-14T22:16:10.432612Z",
     "shell.execute_reply": "2024-04-14T22:16:10.431758Z"
    },
    "papermill": {
     "duration": 0.023231,
     "end_time": "2024-04-14T22:16:10.434497",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.411266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_wikipedia_pages(wiki_wiki, category_name):\n",
    "    \"\"\"Extract all references from a category on Wikipedia\"\"\"\n",
    "    \n",
    "    # Get the Wikipedia page corresponding to the provided category name\n",
    "    category = wiki_wiki.page(\"Category:\" + category_name)\n",
    "    \n",
    "    # Initialize an empty list to store page titles\n",
    "    pages = []\n",
    "    \n",
    "    # Check if the category exists\n",
    "    if category.exists():\n",
    "        # Iterate through each article in the category and append its title to the list\n",
    "        for article in category.categorymembers.values():\n",
    "            pages.append(article.title)\n",
    "    \n",
    "    # Return the list of page titles\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c6814",
   "metadata": {
    "papermill": {
     "duration": 0.013585,
     "end_time": "2024-04-14T22:16:10.462112",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.448527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To gather the information necessary to answer the most tricky questions about Sherlock Holmes and his World, I’ve chosen to begin with a series of topics related to Conan Doyle and his writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1b732b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:16:10.492108Z",
     "iopub.status.busy": "2024-04-14T22:16:10.491249Z",
     "iopub.status.idle": "2024-04-14T22:16:52.595947Z",
     "shell.execute_reply": "2024-04-14T22:16:52.594886Z"
    },
    "papermill": {
     "duration": 42.121726,
     "end_time": "2024-04-14T22:16:52.598000",
     "exception": false,
     "start_time": "2024-04-14T22:16:10.476274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Processing Wikipedia categories:\n",
      "\tExploring Sherlock_Holmes on Wikipedia\n",
      "\tExploring Arthur_Conan_Doyle on Wikipedia\n",
      "\tExploring A_Scandal_in_Bohemia on Wikipedia\n",
      "\tExploring The_Adventures_of_Sherlock_Holmes on Wikipedia\n",
      "\tExploring A_Study_in_Scarlet on Wikipedia\n",
      "\tExploring The_Sign_of_the_Four on Wikipedia\n",
      "\tExploring The_Memoirs_of_Sherlock_Holmes on Wikipedia\n",
      "\tExploring The_Hound_of_the_Baskervilles on Wikipedia\n",
      "\tExploring The_Return_of_Sherlock_Holmes on Wikipedia\n",
      "\tExploring The_Valley_of_Fear on Wikipedia\n",
      "\tExploring His_Last_Bow on Wikipedia\n",
      "\tExploring The_Case-Book_of_Sherlock_Holmes on Wikipedia\n",
      "\tExploring Canon_of_Sherlock_Holmes on Wikipedia\n",
      "\tExploring Dr._Watson on Wikipedia\n",
      "\tExploring 221B_Baker_Street on Wikipedia\n",
      "\tExploring Mrs._Hudson on Wikipedia\n",
      "\tExploring Professor_Moriarty on Wikipedia\n",
      "\tExploring The_Strand_Magazine on Wikipedia\n",
      "\tExploring Works originally published in The Strand Magazine on Wikipedia\n",
      "\tExploring Non-free The Strand Magazine magazine covers on Wikipedia\n",
      "\tExploring The Strand Magazine editors on Wikipedia\n",
      "\tExploring Films based on The Hound of the Baskervilles on Wikipedia\n",
      "\tExploring Works by Arthur Conan Doyle on Wikipedia\n",
      "\tExploring Cultural depictions of Arthur Conan Doyle on Wikipedia\n",
      "\tExploring Arthur Conan Doyle characters on Wikipedia\n",
      "\tExploring Works based on Sherlock Holmes on Wikipedia\n",
      "\tExploring Sherlock Holmes short story collections on Wikipedia\n",
      "\tExploring Sherlock Holmes short stories on Wikipedia\n",
      "\tExploring Sherlock Holmes scholars on Wikipedia\n",
      "\tExploring Sherlock Holmes novels on Wikipedia\n",
      "\tExploring Sherlock Holmes navigational boxes on Wikipedia\n",
      "\tExploring Sherlock Holmes lists on Wikipedia\n",
      "\tExploring Dartmoor on Wikipedia\n",
      "\tExploring Sherlock Holmes characters on Wikipedia\n",
      "- Processing Wikipedia pages:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 536/536 [00:38<00:00, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2451 Wikipedia pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "categories = [\"Sherlock_Holmes\", \"Arthur_Conan_Doyle\", \"A_Scandal_in_Bohemia\",\n",
    "              \"The_Adventures_of_Sherlock_Holmes\", \"A_Study_in_Scarlet\", \"The_Sign_of_the_Four\",\n",
    "              \"The_Memoirs_of_Sherlock_Holmes\", \"The_Hound_of_the_Baskervilles\",\n",
    "              \"The_Return_of_Sherlock_Holmes\", \"The_Valley_of_Fear\", \"His_Last_Bow\", \n",
    "              \"The_Case-Book_of_Sherlock_Holmes\", \"Canon_of_Sherlock_Holmes\", \"Dr._Watson\",\n",
    "              \"221B_Baker_Street\", \"Mrs._Hudson\", \"Professor_Moriarty\", \"The_Strand_Magazine\",\n",
    "             ]\n",
    "extracted_texts = get_wikipedia_pages(categories)\n",
    "print(\"Found\", len(extracted_texts), \"Wikipedia pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac13cbe",
   "metadata": {
    "papermill": {
     "duration": 0.036623,
     "end_time": "2024-04-14T22:16:52.671271",
     "exception": false,
     "start_time": "2024-04-14T22:16:52.634648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2: convert the knowledge base into a Q&A dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59690961",
   "metadata": {
    "papermill": {
     "duration": 0.035771,
     "end_time": "2024-04-14T22:16:52.743256",
     "exception": false,
     "start_time": "2024-04-14T22:16:52.707485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, having collected our knowledge base on Sherlock Holmes, we need to leverage Gemma to convert it into something more useful for training a model. The idea is to use a Q&A approach (e.g. Q: What is Sherlock’s nemesis? A: Prof. Moriarty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d424d9",
   "metadata": {
    "papermill": {
     "duration": 0.04784,
     "end_time": "2024-04-14T22:16:52.831510",
     "exception": false,
     "start_time": "2024-04-14T22:16:52.783670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, let’s upload Gemma 2b-it into memory by quantizing it into a 4-bit version using BitsAndBytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd09c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:16:52.911100Z",
     "iopub.status.busy": "2024-04-14T22:16:52.910650Z",
     "iopub.status.idle": "2024-04-14T22:17:28.140897Z",
     "shell.execute_reply": "2024-04-14T22:17:28.139846Z"
    },
    "papermill": {
     "duration": 35.272475,
     "end_time": "2024-04-14T22:17:28.143345",
     "exception": false,
     "start_time": "2024-04-14T22:16:52.870870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165bf470b8764667abffa07759f83ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"/kaggle/input/gemma/transformers/2b-it/3\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 1024\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bbe0f0",
   "metadata": {
    "papermill": {
     "duration": 0.036083,
     "end_time": "2024-04-14T22:17:28.216841",
     "exception": false,
     "start_time": "2024-04-14T22:17:28.180758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A simple function can wrap up all the steps necessary to inquire about Gemma on a topic or pose a question. The function allows for the pointing out of different temperatures and can return the answer as a stdout or a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9387b76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:28.292405Z",
     "iopub.status.busy": "2024-04-14T22:17:28.291524Z",
     "iopub.status.idle": "2024-04-14T22:17:28.298644Z",
     "shell.execute_reply": "2024-04-14T22:17:28.297766Z"
    },
    "papermill": {
     "duration": 0.047387,
     "end_time": "2024-04-14T22:17:28.300710",
     "exception": false,
     "start_time": "2024-04-14T22:17:28.253323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def question_gemma(question, model=model, tokenizer=tokenizer, temperature=0.0, return_answer=False):\n",
    "    input_ids = tokenizer(question, return_tensors=\"pt\").to(\"cuda\")\n",
    "    if temperature > 0:\n",
    "        do_sample=True\n",
    "    else:\n",
    "        do_sample=False\n",
    "    outputs = model.generate(**input_ids, \n",
    "                             max_new_tokens=256, \n",
    "                             do_sample=do_sample, \n",
    "                             temperature=temperature)\n",
    "    result = str(tokenizer.decode(outputs[0])).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").strip()\n",
    "    if return_answer:\n",
    "        return result\n",
    "    else:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e60d4d",
   "metadata": {
    "papermill": {
     "duration": 0.035792,
     "end_time": "2024-04-14T22:17:28.372608",
     "exception": false,
     "start_time": "2024-04-14T22:17:28.336816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can immediately test it on some general questions about Sherlock Holmes. You will be amazed by the answers! Gemma 2b is already quite knowledgeable about Sherlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b9dc30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:28.448535Z",
     "iopub.status.busy": "2024-04-14T22:17:28.447701Z",
     "iopub.status.idle": "2024-04-14T22:17:31.519277Z",
     "shell.execute_reply": "2024-04-14T22:17:31.518266Z"
    },
    "papermill": {
     "duration": 3.111585,
     "end_time": "2024-04-14T22:17:31.521259",
     "exception": false,
     "start_time": "2024-04-14T22:17:28.409674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was Sherlock Holmes a real person?\n",
      "\n",
      "The premise of your question is incorrect. Sherlock Holmes is a fictional character in literature and not a real person.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"Was Sherlock Holmes a real person?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffc568dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:31.597601Z",
     "iopub.status.busy": "2024-04-14T22:17:31.596939Z",
     "iopub.status.idle": "2024-04-14T22:17:42.825074Z",
     "shell.execute_reply": "2024-04-14T22:17:42.824142Z"
    },
    "papermill": {
     "duration": 11.268792,
     "end_time": "2024-04-14T22:17:42.827316",
     "exception": false,
     "start_time": "2024-04-14T22:17:31.558524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is Sherlock Holmes so smart?\n",
      "\n",
      "Sherlock Holmes is one of the most brilliant and complex characters in literature. He is known for his sharp intellect, deductive reasoning, and observation skills. How is he so smart?\n",
      "\n",
      "**1. Analytical Mind:**\n",
      "Sherlock Holmes is an analytical thinker who can break down complex problems into smaller, more manageable pieces. He is able to identify patterns and relationships between different pieces of information, which allows him to deduce conclusions that are not immediately obvious.\n",
      "\n",
      "**2. Deductive Reasoning:**\n",
      "Sherlock Holmes is a master of deductive reasoning. He is able to draw conclusions from a single piece of evidence, and he is always looking for patterns and inconsistencies in evidence. This allows him to solve mysteries and identify the truth behind the deception.\n",
      "\n",
      "**3. Observation Skills:**\n",
      "Sherlock Holmes is an expert observer who can notice even the smallest details in a scene. He is able to use these details to piece together the truth and to identify the guilty party.\n",
      "\n",
      "**4. Imagination and Creativity:**\n",
      "Sherlock Holmes is a highly imaginative and creative character. He is able to come up with new ideas and solutions to problems, which allows him to outsmart his opponents.\n",
      "\n",
      "**5. Perseverance and Determination:**\n",
      "Sherlock Holmes is a persistent and determined character who will not give up\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"How is Sherlock Holmes so smart?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fb45359",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:42.902749Z",
     "iopub.status.busy": "2024-04-14T22:17:42.901895Z",
     "iopub.status.idle": "2024-04-14T22:17:43.690225Z",
     "shell.execute_reply": "2024-04-14T22:17:43.689105Z"
    },
    "papermill": {
     "duration": 0.828512,
     "end_time": "2024-04-14T22:17:43.692316",
     "exception": false,
     "start_time": "2024-04-14T22:17:42.863804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does Sherlock Holmes die in the The Adventure of the Final Problem?\n",
      "\n",
      "No, Sherlock Holmes does not die in The Adventure of the Final Problem.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"Does Sherlock Holmes die in the The Adventure of the Final Problem?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4e2e0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:43.769154Z",
     "iopub.status.busy": "2024-04-14T22:17:43.768772Z",
     "iopub.status.idle": "2024-04-14T22:17:45.185321Z",
     "shell.execute_reply": "2024-04-14T22:17:45.184437Z"
    },
    "papermill": {
     "duration": 1.457332,
     "end_time": "2024-04-14T22:17:45.187581",
     "exception": false,
     "start_time": "2024-04-14T22:17:43.730249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Sherlock Holmes’s nemesis?\n",
      "\n",
      "The answer is Professor Moriarty.\n",
      "\n",
      "Professor Moriarty is a fictional character in Sherlock Holmes stories. He is a brilliant criminal who is Holmes's nemesis.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"Who is Sherlock Holmes’s nemesis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bf2732a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:45.262485Z",
     "iopub.status.busy": "2024-04-14T22:17:45.261906Z",
     "iopub.status.idle": "2024-04-14T22:17:47.984368Z",
     "shell.execute_reply": "2024-04-14T22:17:47.983177Z"
    },
    "papermill": {
     "duration": 2.762192,
     "end_time": "2024-04-14T22:17:47.986597",
     "exception": false,
     "start_time": "2024-04-14T22:17:45.224405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does Sherlock Holmes have a museum?\n",
      "\n",
      "Yes, Sherlock Holmes does have a museum in Baker Street, London, England. It is called the Baker Street Gallery and is a museum dedicated to the life and work of Sherlock Holmes. The museum houses a collection of Holmes's personal belongings, including his personal library, furniture, and other items.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"Does Sherlock Holmes have a museum?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ff34d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:48.063826Z",
     "iopub.status.busy": "2024-04-14T22:17:48.063004Z",
     "iopub.status.idle": "2024-04-14T22:17:51.237584Z",
     "shell.execute_reply": "2024-04-14T22:17:51.236535Z"
    },
    "papermill": {
     "duration": 3.215355,
     "end_time": "2024-04-14T22:17:51.239688",
     "exception": false,
     "start_time": "2024-04-14T22:17:48.024333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In what Sherlock Holmes is knowledgable?\n",
      "\n",
      "Sherlock Holmes is knowledgeable in a wide range of subjects, including:\n",
      "\n",
      "- Forensic science\n",
      "- Criminology\n",
      "- Logic\n",
      "- Deduction\n",
      "- History\n",
      "- Literature\n",
      "- Music\n",
      "- Art\n",
      "- Science\n",
      "- Medicine\n",
      "\n",
      "He is also a master of disguise and deception, and he often uses his knowledge to outsmart his opponents.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"In what Sherlock Holmes is knowledgable?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adbfed96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:51.316521Z",
     "iopub.status.busy": "2024-04-14T22:17:51.315678Z",
     "iopub.status.idle": "2024-04-14T22:17:52.872986Z",
     "shell.execute_reply": "2024-04-14T22:17:52.871918Z"
    },
    "papermill": {
     "duration": 1.597452,
     "end_time": "2024-04-14T22:17:52.875123",
     "exception": false,
     "start_time": "2024-04-14T22:17:51.277671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was Arthur Conan Doyle's belief about paranormal phenomena?\n",
      "\n",
      "Arthur Conan Doyle was a staunch skeptic and did not believe in paranormal phenomena. He was skeptical of any claims that could not be verified through scientific observation or logic.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"What was Arthur Conan Doyle's belief about paranormal phenomena?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfc258",
   "metadata": {
    "papermill": {
     "duration": 0.036837,
     "end_time": "2024-04-14T22:17:52.949455",
     "exception": false,
     "start_time": "2024-04-14T22:17:52.912618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Quite impressive! However, we want to become even more experts and learn the most intricate facts about Sherlock Holmes and his creator, Sir Arthur Conan Doyle. Hence, we iterate through the Wikipedia knowledge base, asking Gemma to produce a question and answer it from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3bd1d4",
   "metadata": {
    "papermill": {
     "duration": 0.037088,
     "end_time": "2024-04-14T22:17:53.024023",
     "exception": false,
     "start_time": "2024-04-14T22:17:52.986935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using all of the knowledge base and posing multiple answers derived from the same text will help build out fine-tuning training data. Asking multiple answers is a necessity because Gemma will pick just a topic from the test, and it will tend to answer briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e919473",
   "metadata": {
    "papermill": {
     "duration": 0.036402,
     "end_time": "2024-04-14T22:17:53.097473",
     "exception": false,
     "start_time": "2024-04-14T22:17:53.061071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can control how Gemma returns the question and answer, proposing it to return a JSON file in the form {“question”: “…”, “answer”: “…”}. Hence, it will be easy to retrieve the data from the output text utilizing regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8126382d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:17:53.172517Z",
     "iopub.status.busy": "2024-04-14T22:17:53.171783Z",
     "iopub.status.idle": "2024-04-14T22:31:50.632699Z",
     "shell.execute_reply": "2024-04-14T22:31:50.631740Z"
    },
    "papermill": {
     "duration": 837.501407,
     "end_time": "2024-04-14T22:31:50.635508",
     "exception": false,
     "start_time": "2024-04-14T22:17:53.134101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [13:57<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "qa_data = []\n",
    "\n",
    "def extract_json(text, word):\n",
    "    pattern = fr'\"{word}\": \"(.*?)\"'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "no_extracted_texts = 300 # increment this number up to len(extracted_texts)\n",
    "question_ratio = 24 # decrement this number to produce more questions (suggested: 24)\n",
    "\n",
    "for i in tqdm(range(len(extracted_texts[:no_extracted_texts]))):\n",
    "\n",
    "    question_text = f\"\"\"Create a question and its answer from the following piece of information,\n",
    "    put all the necessary information into the question (do not assume the reader knows the text),\n",
    "    and return it exclusively in JSON format in the format {'{\"question\": \"...\", \"answer\": \"...\"}'}\n",
    "\n",
    "    Here is the piece of information to elaborate:\n",
    "    {extracted_texts[i]}\n",
    "\n",
    "    OUTPUT JSON:\n",
    "    \"\"\"\n",
    "\n",
    "    no_questions = min(1, len(extracted_texts[i]) // question_ratio)\n",
    "    for j in range(no_questions):\n",
    "    \n",
    "        result = question_gemma(question_text, model=model, temperature=0.9, return_answer=True)\n",
    "        result = result.split(\"OUTPUT JSON:\")[-1]\n",
    "\n",
    "        question = extract_json(result, \"question\")\n",
    "        answer = extract_json(result, \"answer\")\n",
    "\n",
    "        qa_data.append(f\"{question}\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d9c9de",
   "metadata": {
    "papermill": {
     "duration": 0.05986,
     "end_time": "2024-04-14T22:31:50.756604",
     "exception": false,
     "start_time": "2024-04-14T22:31:50.696744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that the dataset has been gathered, it is time to turn it into an HF Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "900fe89e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:31:50.880462Z",
     "iopub.status.busy": "2024-04-14T22:31:50.879809Z",
     "iopub.status.idle": "2024-04-14T22:31:50.924995Z",
     "shell.execute_reply": "2024-04-14T22:31:50.924181Z"
    },
    "papermill": {
     "duration": 0.110108,
     "end_time": "2024-04-14T22:31:50.927187",
     "exception": false,
     "start_time": "2024-04-14T22:31:50.817079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_length = 1024\n",
    "\n",
    "train_data = (pd.DataFrame(qa_data, columns=[\"text\"])\n",
    "              .sample(frac=1, random_state=5)\n",
    "              .drop_duplicates()\n",
    "             )\n",
    "train_data = Dataset.from_pandas(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693fdf29",
   "metadata": {
    "papermill": {
     "duration": 0.061057,
     "end_time": "2024-04-14T22:31:51.050310",
     "exception": false,
     "start_time": "2024-04-14T22:31:50.989253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 3: fine-tune the Gemma model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d81dcd",
   "metadata": {
    "papermill": {
     "duration": 0.060122,
     "end_time": "2024-04-14T22:31:51.171116",
     "exception": false,
     "start_time": "2024-04-14T22:31:51.110994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the following cells, LoRA is set, and the training parameters are defined. Afterward, the fine-tuning can start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48c64000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:31:51.295334Z",
     "iopub.status.busy": "2024-04-14T22:31:51.294575Z",
     "iopub.status.idle": "2024-04-14T22:31:51.323203Z",
     "shell.execute_reply": "2024-04-14T22:31:51.322454Z"
    },
    "papermill": {
     "duration": 0.093003,
     "end_time": "2024-04-14T22:31:51.325230",
     "exception": false,
     "start_time": "2024-04-14T22:31:51.232227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"gemma_sherlock\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=1,\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=False,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps = 500,\n",
    "    eval_accumulation_steps=1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078fb2dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:31:51.450563Z",
     "iopub.status.busy": "2024-04-14T22:31:51.449685Z",
     "iopub.status.idle": "2024-04-14T22:31:53.332972Z",
     "shell.execute_reply": "2024-04-14T22:31:53.332134Z"
    },
    "papermill": {
     "duration": 1.948791,
     "end_time": "2024-04-14T22:31:53.335109",
     "exception": false,
     "start_time": "2024-04-14T22:31:51.386318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356b31fe800344d6b0425b682c689156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741dd7d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:31:53.462381Z",
     "iopub.status.busy": "2024-04-14T22:31:53.461524Z",
     "iopub.status.idle": "2024-04-14T22:33:42.997963Z",
     "shell.execute_reply": "2024-04-14T22:33:42.997060Z"
    },
    "papermill": {
     "duration": 109.60239,
     "end_time": "2024-04-14T22:33:42.999944",
     "exception": false,
     "start_time": "2024-04-14T22:31:53.397554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 01:45, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37, training_loss=2.886970932419236, metrics={'train_runtime': 109.142, 'train_samples_per_second': 2.749, 'train_steps_per_second': 0.339, 'total_flos': 119441509195776.0, 'train_loss': 2.886970932419236, 'epoch': 0.99})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584992aa",
   "metadata": {
    "papermill": {
     "duration": 0.060575,
     "end_time": "2024-04-14T22:33:43.121635",
     "exception": false,
     "start_time": "2024-04-14T22:33:43.061060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After we finish, we can ask a tricky question. Gemma's ability to answer depends on how good the Q&A data previously produced was! Remember, the more data is extracted, the better (redundancy is also better—i.e., similar questions with differently arranged answers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a62a6b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:33:43.245591Z",
     "iopub.status.busy": "2024-04-14T22:33:43.244838Z",
     "iopub.status.idle": "2024-04-14T22:33:46.384870Z",
     "shell.execute_reply": "2024-04-14T22:33:46.383885Z"
    },
    "papermill": {
     "duration": 3.204474,
     "end_time": "2024-04-14T22:33:46.386936",
     "exception": false,
     "start_time": "2024-04-14T22:33:43.182462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was Arthur Conan Doyle's belief about paranormal phenomena?\n",
      "Doyle believed that paranormal phenomena was real and that it was caused by a combination of factors, including the human imagination, the subconscious, and the environment.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"What was Arthur Conan Doyle's belief about paranormal phenomena?\",\n",
    "                model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6480913b",
   "metadata": {
    "papermill": {
     "duration": 0.060624,
     "end_time": "2024-04-14T22:33:46.509367",
     "exception": false,
     "start_time": "2024-04-14T22:33:46.448743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Amazed that the answer is different from the un-tunned Gemma? Actually, the following answer is more correct (read: https://blog.bookstellyouwhy.com/sir-arthur-conan-doyles-proclivity-for-the-paranormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8fb6c",
   "metadata": {
    "papermill": {
     "duration": 0.063018,
     "end_time": "2024-04-14T22:33:46.633106",
     "exception": false,
     "start_time": "2024-04-14T22:33:46.570088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 4: save the LoRA weights and merge them into Gemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8cb13",
   "metadata": {
    "papermill": {
     "duration": 0.061016,
     "end_time": "2024-04-14T22:33:46.755665",
     "exception": false,
     "start_time": "2024-04-14T22:33:46.694649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, the tricky part is saving the trained LoRA weights, reloading them, and merging them with the Gemma original model. The result is our new fine-tuned Gemma!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2df708c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:33:46.881151Z",
     "iopub.status.busy": "2024-04-14T22:33:46.880382Z",
     "iopub.status.idle": "2024-04-14T22:33:48.689020Z",
     "shell.execute_reply": "2024-04-14T22:33:48.687801Z"
    },
    "papermill": {
     "duration": 1.874353,
     "end_time": "2024-04-14T22:33:48.691679",
     "exception": false,
     "start_time": "2024-04-14T22:33:46.817326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma_sherlock/tokenizer_config.json',\n",
       " 'gemma_sherlock/special_tokens_map.json',\n",
       " 'gemma_sherlock/tokenizer.model',\n",
       " 'gemma_sherlock/added_tokens.json',\n",
       " 'gemma_sherlock/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f4c15",
   "metadata": {
    "papermill": {
     "duration": 0.06231,
     "end_time": "2024-04-14T22:33:48.815882",
     "exception": false,
     "start_time": "2024-04-14T22:33:48.753572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This cell cleans up the CPU and GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89d9af26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:33:48.955572Z",
     "iopub.status.busy": "2024-04-14T22:33:48.954919Z",
     "iopub.status.idle": "2024-04-14T22:33:51.930826Z",
     "shell.execute_reply": "2024-04-14T22:33:51.929983Z"
    },
    "papermill": {
     "duration": 3.042054,
     "end_time": "2024-04-14T22:33:51.933175",
     "exception": false,
     "start_time": "2024-04-14T22:33:48.891121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del [model, tokenizer, peft_config, trainer, train_data, bnb_config, training_arguments]\n",
    "del [TrainingArguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]\n",
    "\n",
    "for _ in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bda10",
   "metadata": {
    "papermill": {
     "duration": 0.064346,
     "end_time": "2024-04-14T22:33:52.064764",
     "exception": false,
     "start_time": "2024-04-14T22:33:52.000418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we proceed to the merging procedure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1093af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:33:52.190351Z",
     "iopub.status.busy": "2024-04-14T22:33:52.189988Z",
     "iopub.status.idle": "2024-04-14T22:34:12.298873Z",
     "shell.execute_reply": "2024-04-14T22:34:12.297896Z"
    },
    "papermill": {
     "duration": 20.174931,
     "end_time": "2024-04-14T22:34:12.301532",
     "exception": false,
     "start_time": "2024-04-14T22:33:52.126601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92656650c5414714a43c566ba0bd50b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./gemma_sherlock_merged/tokenizer_config.json',\n",
       " './gemma_sherlock_merged/special_tokens_map.json',\n",
       " './gemma_sherlock_merged/tokenizer.model',\n",
       " './gemma_sherlock_merged/added_tokens.json',\n",
       " './gemma_sherlock_merged/tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = output_dir\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "     finetuned_model,\n",
    "     torch_dtype=compute_dtype,\n",
    "     return_dict=False,\n",
    "     low_cpu_mem_usage=True,\n",
    "     device_map=\"auto\",\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\"./gemma_sherlock_merged\",\n",
    "                             safe_serialization=True, \n",
    "                             max_shard_size=\"2GB\")\n",
    "tokenizer.save_pretrained(\"./gemma_sherlock_merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce61a1",
   "metadata": {
    "papermill": {
     "duration": 0.283339,
     "end_time": "2024-04-14T22:34:13.904677",
     "exception": false,
     "start_time": "2024-04-14T22:34:13.621338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again, memory cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b611789f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:34:14.073922Z",
     "iopub.status.busy": "2024-04-14T22:34:14.072508Z",
     "iopub.status.idle": "2024-04-14T22:34:17.373547Z",
     "shell.execute_reply": "2024-04-14T22:34:17.372682Z"
    },
    "papermill": {
     "duration": 3.382699,
     "end_time": "2024-04-14T22:34:17.375840",
     "exception": false,
     "start_time": "2024-04-14T22:34:13.993141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del [model, tokenizer, merged_model, AutoPeftModelForCausalLM]\n",
    "\n",
    "for _ in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "190b690f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:34:17.503499Z",
     "iopub.status.busy": "2024-04-14T22:34:17.503142Z",
     "iopub.status.idle": "2024-04-14T22:34:20.503794Z",
     "shell.execute_reply": "2024-04-14T22:34:20.502905Z"
    },
    "papermill": {
     "duration": 3.066785,
     "end_time": "2024-04-14T22:34:20.506075",
     "exception": false,
     "start_time": "2024-04-14T22:34:17.439290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27ae2a8",
   "metadata": {
    "papermill": {
     "duration": 0.061744,
     "end_time": "2024-04-14T22:34:20.631883",
     "exception": false,
     "start_time": "2024-04-14T22:34:20.570139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The final step is reloading the fine-tuned model and try using it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9083ecae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:34:20.759765Z",
     "iopub.status.busy": "2024-04-14T22:34:20.759031Z",
     "iopub.status.idle": "2024-04-14T22:34:24.456707Z",
     "shell.execute_reply": "2024-04-14T22:34:24.455867Z"
    },
    "papermill": {
     "duration": 3.764049,
     "end_time": "2024-04-14T22:34:24.458988",
     "exception": false,
     "start_time": "2024-04-14T22:34:20.694939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d17e11aaded4593aaa66bcfc845cc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig)\n",
    "\n",
    "model_name = \"./gemma_sherlock_merged\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 1024\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b739f89",
   "metadata": {
    "papermill": {
     "duration": 0.063622,
     "end_time": "2024-04-14T22:34:24.585278",
     "exception": false,
     "start_time": "2024-04-14T22:34:24.521656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now it is time for the last test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea678a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T22:34:24.712233Z",
     "iopub.status.busy": "2024-04-14T22:34:24.711857Z",
     "iopub.status.idle": "2024-04-14T22:34:33.832490Z",
     "shell.execute_reply": "2024-04-14T22:34:33.830594Z"
    },
    "papermill": {
     "duration": 9.188178,
     "end_time": "2024-04-14T22:34:33.835154",
     "exception": false,
     "start_time": "2024-04-14T22:34:24.646976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was the Strand magazine?\n",
      "The Strand magazine was a British magazine that was founded in 1903 by George Newnes. It was a popular magazine for both men and women, and it was known for its high-quality photography and writing. The magazine was also known for its political and social commentary. The Strand magazine was also a pioneer in the field of photography, and it was one of the first magazines to use color photography. The magazine was also a pioneer in the field of advertising, and it was one of the first magazines to use advertising to promote its content. The Strand magazine was also a pioneer in the field of publishing, and it was one of the first magazines to publish a full-length novel. The magazine was also a pioneer in the field of publishing, and it was one of the first magazines to publish a full-length novel. The Strand magazine was a pioneer in the field of publishing, and it was one of the most influential magazines of the early 20th century.\n"
     ]
    }
   ],
   "source": [
    "question_gemma(\"What was the Strand magazine?\",\n",
    "                model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b5715",
   "metadata": {
    "papermill": {
     "duration": 0.066786,
     "end_time": "2024-04-14T22:34:33.976375",
     "exception": false,
     "start_time": "2024-04-14T22:34:33.909589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Nice answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5dcc1",
   "metadata": {
    "papermill": {
     "duration": 0.065918,
     "end_time": "2024-04-14T22:34:34.109684",
     "exception": false,
     "start_time": "2024-04-14T22:34:34.043766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We conclude the tutorial here. By following the same steps, you can fine-tune Gemma for any topic.\n",
    "\n",
    "Enjoy fine-tuning with Google Gemma!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc99ca",
   "metadata": {
    "papermill": {
     "duration": 0.062038,
     "end_time": "2024-04-14T22:34:34.235277",
     "exception": false,
     "start_time": "2024-04-14T22:34:34.173239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelInstanceId": 8318,
     "sourceId": 28785,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1235.886709,
   "end_time": "2024-04-14T22:34:37.066614",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-14T22:14:01.179905",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "097400666b1344a087d0bff2e1804d72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0ae0a00ac2a44daa87e2b978fedb8b4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c723e5dbdcc405f99d3ccaac6b5763b",
       "placeholder": "​",
       "style": "IPY_MODEL_7075fc5114c042c5869041986ef9dea2",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "0fb2bf0b7a394f958043cea81e724cc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "165bf470b8764667abffa07759f83ca0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c76535b5ef7740fab7f591fd0493e99e",
        "IPY_MODEL_deb803d08cee4fde87bc32dff83f68f8",
        "IPY_MODEL_b16a1c76c4db45a2a8c634a2c9bb6251"
       ],
       "layout": "IPY_MODEL_b6e053f6c17748f1bd8a4d60b6ec7f23"
      }
     },
     "2159716aed0748a79e83d6a2ce0c6c73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d3345c6d02334443b22b78411d66d9d3",
       "placeholder": "​",
       "style": "IPY_MODEL_2f1b49cbc72843c3ada80b49f484b0db",
       "value": " 2/2 [00:04&lt;00:00,  1.94s/it]"
      }
     },
     "295032bc93b6413799b140cace27f649": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2dfaec2d211f4f1eb3869a09efe17871": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2f1b49cbc72843c3ada80b49f484b0db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "356b31fe800344d6b0425b682c689156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a5b7490bb97d4b07a4b646626c4e154b",
        "IPY_MODEL_44ec56835cb44b6f9e93fc7f3cf0fb30",
        "IPY_MODEL_7cd2ceaecce6497ba3cd99e72376830a"
       ],
       "layout": "IPY_MODEL_a66210a3813f4760947020283c942316"
      }
     },
     "39c37a5e817b40fa9985aafbb1fea40c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44ec56835cb44b6f9e93fc7f3cf0fb30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a425bb9ba2cc442990e4d184e4a9090b",
       "max": 300.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0fb2bf0b7a394f958043cea81e724cc0",
       "value": 300.0
      }
     },
     "46090d87278f414d9a098d36ff1a89f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "498fc7461bad407b9a973624a0bface5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4c723e5dbdcc405f99d3ccaac6b5763b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56896f9d7d20470690e150e7c7fb7fbd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7075fc5114c042c5869041986ef9dea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "75c64911240c4b849daac2fdfc01b867": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7cd2ceaecce6497ba3cd99e72376830a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39c37a5e817b40fa9985aafbb1fea40c",
       "placeholder": "​",
       "style": "IPY_MODEL_e6c3a3afe0444ff4b5ad78e6478aaca7",
       "value": " 300/300 [00:00&lt;00:00, 4012.37 examples/s]"
      }
     },
     "92656650c5414714a43c566ba0bd50b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ae0a00ac2a44daa87e2b978fedb8b4a",
        "IPY_MODEL_dcd1b5df713a479986f59536b84d0d77",
        "IPY_MODEL_2159716aed0748a79e83d6a2ce0c6c73"
       ],
       "layout": "IPY_MODEL_9d4a1c426c7e4f1babe6f72b74edf17e"
      }
     },
     "98058d2b040f4807a38cbe5c6d0ec93c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "988e3790ccc0454085d9e86c39e56919": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9d17e11aaded4593aaa66bcfc845cc56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eec9b5d222c5434d8a82501b459fd3fd",
        "IPY_MODEL_d612f8326e7b45a4b08375293db3cb93",
        "IPY_MODEL_ff26add5d4074207b7d32350d4985913"
       ],
       "layout": "IPY_MODEL_46090d87278f414d9a098d36ff1a89f3"
      }
     },
     "9d4a1c426c7e4f1babe6f72b74edf17e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a1f76223065240459beaa7bddb5db6a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a425bb9ba2cc442990e4d184e4a9090b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5b7490bb97d4b07a4b646626c4e154b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef8d9784ad514fb6b729c821f417bd52",
       "placeholder": "​",
       "style": "IPY_MODEL_2dfaec2d211f4f1eb3869a09efe17871",
       "value": "Map: 100%"
      }
     },
     "a66210a3813f4760947020283c942316": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b16a1c76c4db45a2a8c634a2c9bb6251": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fe4143d3a93b404fa272c4c7e8177a12",
       "placeholder": "​",
       "style": "IPY_MODEL_295032bc93b6413799b140cace27f649",
       "value": " 2/2 [00:33&lt;00:00, 13.93s/it]"
      }
     },
     "b684ac6036504b2293809ce1e9fdfabd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6e053f6c17748f1bd8a4d60b6ec7f23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bee113a4b199407eb2bab48bbafd4c25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c76535b5ef7740fab7f591fd0493e99e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bee113a4b199407eb2bab48bbafd4c25",
       "placeholder": "​",
       "style": "IPY_MODEL_98058d2b040f4807a38cbe5c6d0ec93c",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "d3345c6d02334443b22b78411d66d9d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d612f8326e7b45a4b08375293db3cb93": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db06b0db4cd1469fbe6a0a264a5b1ef2",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_498fc7461bad407b9a973624a0bface5",
       "value": 3.0
      }
     },
     "d74d9f0adab047149afa3af32fee6804": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "db06b0db4cd1469fbe6a0a264a5b1ef2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcd1b5df713a479986f59536b84d0d77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b684ac6036504b2293809ce1e9fdfabd",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d74d9f0adab047149afa3af32fee6804",
       "value": 2.0
      }
     },
     "dcd937dd42944896873e793d5ecba51b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deb803d08cee4fde87bc32dff83f68f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_56896f9d7d20470690e150e7c7fb7fbd",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_988e3790ccc0454085d9e86c39e56919",
       "value": 2.0
      }
     },
     "e6c3a3afe0444ff4b5ad78e6478aaca7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "eec9b5d222c5434d8a82501b459fd3fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dcd937dd42944896873e793d5ecba51b",
       "placeholder": "​",
       "style": "IPY_MODEL_75c64911240c4b849daac2fdfc01b867",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "ef8d9784ad514fb6b729c821f417bd52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe4143d3a93b404fa272c4c7e8177a12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff26add5d4074207b7d32350d4985913": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a1f76223065240459beaa7bddb5db6a4",
       "placeholder": "​",
       "style": "IPY_MODEL_097400666b1344a087d0bff2e1804d72",
       "value": " 3/3 [00:02&lt;00:00,  1.24it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
