{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a14117f",
   "metadata": {
    "papermill": {
     "duration": 0.014856,
     "end_time": "2021-10-04T22:00:12.112617",
     "exception": false,
     "start_time": "2021-10-04T22:00:12.097761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is inspired by recent notebooks from [Zhangxin](https://www.kaggle.com/tenffe/finetune-of-tensorflow-bidirectional-lstm) and [Chris Deotte](https://www.kaggle.com/cdeotte/ensemble-folds-with-median-0-153). Since it is important to dicretize the output, I propose a custom TensorFlow layer that will automatically do that for you. The optimization will therefore happen under contrains that the output should be bounded and discrete as the inputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eccd92b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:00:12.145766Z",
     "iopub.status.busy": "2021-10-04T22:00:12.144562Z",
     "iopub.status.idle": "2021-10-04T22:00:17.148923Z",
     "shell.execute_reply": "2021-10-04T22:00:17.148197Z",
     "shell.execute_reply.started": "2021-10-04T12:12:57.08914Z"
    },
    "papermill": {
     "duration": 5.021606,
     "end_time": "2021-10-04T22:00:17.149086",
     "exception": false,
     "start_time": "2021-10-04T22:00:12.127480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:00:12.649059: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-04 22:00:12.649169: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6b5222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:00:17.183831Z",
     "iopub.status.busy": "2021-10-04T22:00:17.183198Z",
     "iopub.status.idle": "2021-10-04T22:00:32.206810Z",
     "shell.execute_reply": "2021-10-04T22:00:32.205472Z",
     "shell.execute_reply.started": "2021-10-04T12:13:03.5941Z"
    },
    "papermill": {
     "duration": 15.043361,
     "end_time": "2021-10-04T22:00:32.206995",
     "exception": false,
     "start_time": "2021-10-04T22:00:17.163634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "train = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\n",
    "test = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\n",
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "\n",
    "if DEBUG:\n",
    "    train = train[:80*1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a54e405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:00:32.257450Z",
     "iopub.status.busy": "2021-10-04T22:00:32.249988Z",
     "iopub.status.idle": "2021-10-04T22:00:32.267822Z",
     "shell.execute_reply": "2021-10-04T22:00:32.268331Z",
     "shell.execute_reply.started": "2021-10-04T12:13:19.985477Z"
    },
    "papermill": {
     "duration": 0.046425,
     "end_time": "2021-10-04T22:00:32.268613",
     "exception": false,
     "start_time": "2021-10-04T22:00:32.222188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breath_id</th>\n",
       "      <th>R</th>\n",
       "      <th>C</th>\n",
       "      <th>time_step</th>\n",
       "      <th>u_in</th>\n",
       "      <th>u_out</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0</td>\n",
       "      <td>5.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>18.383041</td>\n",
       "      <td>0</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.067514</td>\n",
       "      <td>22.509278</td>\n",
       "      <td>0</td>\n",
       "      <td>7.876254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>22.808822</td>\n",
       "      <td>0</td>\n",
       "      <td>11.742872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.135756</td>\n",
       "      <td>25.355850</td>\n",
       "      <td>0</td>\n",
       "      <td>12.234987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035995</th>\n",
       "      <td>6035996</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.504603</td>\n",
       "      <td>1.489714</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035996</th>\n",
       "      <td>6035997</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.537961</td>\n",
       "      <td>1.488497</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035997</th>\n",
       "      <td>6035998</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.571408</td>\n",
       "      <td>1.558978</td>\n",
       "      <td>1</td>\n",
       "      <td>3.798729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035998</th>\n",
       "      <td>6035999</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.604744</td>\n",
       "      <td>1.272663</td>\n",
       "      <td>1</td>\n",
       "      <td>4.079938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035999</th>\n",
       "      <td>6036000</td>\n",
       "      <td>125749</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>2.638017</td>\n",
       "      <td>1.482739</td>\n",
       "      <td>1</td>\n",
       "      <td>3.869032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6036000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  breath_id   R   C  time_step       u_in  u_out   pressure\n",
       "0              1          1  20  50   0.000000   0.083334      0   5.837492\n",
       "1              2          1  20  50   0.033652  18.383041      0   5.907794\n",
       "2              3          1  20  50   0.067514  22.509278      0   7.876254\n",
       "3              4          1  20  50   0.101542  22.808822      0  11.742872\n",
       "4              5          1  20  50   0.135756  25.355850      0  12.234987\n",
       "...          ...        ...  ..  ..        ...        ...    ...        ...\n",
       "6035995  6035996     125749  50  10   2.504603   1.489714      1   3.869032\n",
       "6035996  6035997     125749  50  10   2.537961   1.488497      1   3.869032\n",
       "6035997  6035998     125749  50  10   2.571408   1.558978      1   3.798729\n",
       "6035998  6035999     125749  50  10   2.604744   1.272663      1   4.079938\n",
       "6035999  6036000     125749  50  10   2.638017   1.482739      1   3.869032\n",
       "\n",
       "[6036000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481732cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:00:32.310178Z",
     "iopub.status.busy": "2021-10-04T22:00:32.301937Z",
     "iopub.status.idle": "2021-10-04T22:00:32.381205Z",
     "shell.execute_reply": "2021-10-04T22:00:32.381697Z",
     "shell.execute_reply.started": "2021-10-04T12:13:20.019002Z"
    },
    "papermill": {
     "duration": 0.097893,
     "end_time": "2021-10-04T22:00:32.381888",
     "exception": false,
     "start_time": "2021-10-04T22:00:32.283995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pressure = sorted(train.pressure.unique())\n",
    "PRESSURE_MIN = np.min(all_pressure)\n",
    "PRESSURE_MAX = np.max(all_pressure)\n",
    "PRESSURE_STEP = all_pressure[1] - all_pressure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0121d5a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:00:32.416199Z",
     "iopub.status.busy": "2021-10-04T22:00:32.415192Z",
     "iopub.status.idle": "2021-10-04T22:00:32.438067Z",
     "shell.execute_reply": "2021-10-04T22:00:32.438744Z",
     "shell.execute_reply.started": "2021-10-04T12:13:20.101216Z"
    },
    "papermill": {
     "duration": 0.041489,
     "end_time": "2021-10-04T22:00:32.438951",
     "exception": false,
     "start_time": "2021-10-04T22:00:32.397462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    \n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    \n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    \n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    \n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "    \n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    \n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865511ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:00:32.476077Z",
     "iopub.status.busy": "2021-10-04T22:00:32.475412Z",
     "iopub.status.idle": "2021-10-04T22:01:24.485489Z",
     "shell.execute_reply": "2021-10-04T22:01:24.484898Z",
     "shell.execute_reply.started": "2021-10-04T12:13:20.124571Z"
    },
    "papermill": {
     "duration": 52.029008,
     "end_time": "2021-10-04T22:01:24.485638",
     "exception": false,
     "start_time": "2021-10-04T22:00:32.456630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = add_features(train)\n",
    "test = add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "226c21ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:01:24.523488Z",
     "iopub.status.busy": "2021-10-04T22:01:24.522032Z",
     "iopub.status.idle": "2021-10-04T22:01:27.930700Z",
     "shell.execute_reply": "2021-10-04T22:01:27.930105Z",
     "shell.execute_reply.started": "2021-10-04T12:14:11.976181Z"
    },
    "papermill": {
     "duration": 3.430018,
     "end_time": "2021-10-04T22:01:27.930858",
     "exception": false,
     "start_time": "2021-10-04T22:01:24.500840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "train.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\n",
    "test = test.drop(['id', 'breath_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfc2d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:01:27.968505Z",
     "iopub.status.busy": "2021-10-04T22:01:27.967831Z",
     "iopub.status.idle": "2021-10-04T22:01:38.826296Z",
     "shell.execute_reply": "2021-10-04T22:01:38.825705Z",
     "shell.execute_reply.started": "2021-10-04T12:14:15.416341Z"
    },
    "papermill": {
     "duration": 10.879779,
     "end_time": "2021-10-04T22:01:38.826477",
     "exception": false,
     "start_time": "2021-10-04T22:01:27.946698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RS = RobustScaler()\n",
    "train = RS.fit_transform(train)\n",
    "test = RS.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c36a4e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:01:38.863138Z",
     "iopub.status.busy": "2021-10-04T22:01:38.861794Z",
     "iopub.status.idle": "2021-10-04T22:01:39.669631Z",
     "shell.execute_reply": "2021-10-04T22:01:39.668978Z",
     "shell.execute_reply.started": "2021-10-04T12:14:26.416456Z"
    },
    "papermill": {
     "duration": 0.828621,
     "end_time": "2021-10-04T22:01:39.669790",
     "exception": false,
     "start_time": "2021-10-04T22:01:38.841169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.reshape(-1, 80, train.shape[-1]).astype(np.float32)\n",
    "test = test.reshape(-1, 80, train.shape[-1]).astype(np.float32)\n",
    "targets = targets.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1c00e",
   "metadata": {
    "papermill": {
     "duration": 0.014299,
     "end_time": "2021-10-04T22:01:39.698965",
     "exception": false,
     "start_time": "2021-10-04T22:01:39.684666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following custom layer will rescale the output to fit the discrete steps in values to be found in the target. In such a way, you will force your network to learn how to provide outputs that do not need further post processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32a372c",
   "metadata": {
    "papermill": {
     "duration": 0.014068,
     "end_time": "2021-10-04T22:01:39.727833",
     "exception": false,
     "start_time": "2021-10-04T22:01:39.713765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Please notice the custom rounding **round_with_gradients** function since tf.round has no gradients and it won't be differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0ce166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:01:39.766255Z",
     "iopub.status.busy": "2021-10-04T22:01:39.765567Z",
     "iopub.status.idle": "2021-10-04T22:01:39.767269Z",
     "shell.execute_reply": "2021-10-04T22:01:39.767734Z",
     "shell.execute_reply.started": "2021-10-04T12:14:27.259471Z"
    },
    "papermill": {
     "duration": 0.025649,
     "end_time": "2021-10-04T22:01:39.767901",
     "exception": false,
     "start_time": "2021-10-04T22:01:39.742252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def round_with_gradients(x):\n",
    "    def grad(dy):\n",
    "        return dy\n",
    "    return tf.round(x), grad\n",
    "\n",
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "        self.min = tf.constant(PRESSURE_MIN, dtype=np.float32)\n",
    "        self.max = tf.constant(PRESSURE_MAX, dtype=np.float32)\n",
    "        self.step = tf.constant(PRESSURE_STEP, dtype=np.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        steps = tf.math.divide(tf.math.add(inputs, -self.min), self.step)\n",
    "        int_steps = round_with_gradients(steps)\n",
    "        rescaled_steps = tf.math.add(tf.math.multiply(int_steps, self.step), self.min)\n",
    "        clipped = tf.clip_by_value(rescaled_steps, self.min, self.max)\n",
    "        return clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d8a581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:01:39.799688Z",
     "iopub.status.busy": "2021-10-04T22:01:39.799082Z",
     "iopub.status.idle": "2021-10-04T22:01:39.802124Z",
     "shell.execute_reply": "2021-10-04T22:01:39.802609Z",
     "shell.execute_reply.started": "2021-10-04T12:14:27.269732Z"
    },
    "papermill": {
     "duration": 0.020287,
     "end_time": "2021-10-04T22:01:39.802764",
     "exception": false,
     "start_time": "2021-10-04T22:01:39.782477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCH = 300\n",
    "BATCH_SIZE = 1024\n",
    "NUM_FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "940a969a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-04T22:01:39.835482Z",
     "iopub.status.busy": "2021-10-04T22:01:39.834822Z",
     "iopub.status.idle": "2021-10-05T03:19:18.283799Z",
     "shell.execute_reply": "2021-10-05T03:19:18.282751Z"
    },
    "papermill": {
     "duration": 19058.466868,
     "end_time": "2021-10-05T03:19:18.284053",
     "exception": false,
     "start_time": "2021-10-04T22:01:39.817185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:01:39.849151: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-04 22:01:39.852060: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-04 22:01:39.852095: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-04 22:01:39.852119: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f34fb7d148bb): /proc/driver/nvidia/version does not exist\n",
      "2021-10-04 22:01:39.854459: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-04 22:01:39.855975: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-04 22:01:39.860866: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-04 22:01:39.883163: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2021-10-04 22:01:39.883218: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30022}\n",
      "2021-10-04 22:01:39.912546: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2021-10-04 22:01:39.912600: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30022}\n",
      "2021-10-04 22:01:39.913903: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- > Fold 1 < ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:02:00.471394: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 54s 420ms/step - loss: 4.0541 - val_loss: 1.2423\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24230, saving model to folds0.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 1.1029 - val_loss: 0.8046\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.24230 to 0.80458, saving model to folds0.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.7512 - val_loss: 0.6178\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.80458 to 0.61779, saving model to folds0.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.6442 - val_loss: 0.6388\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.61779\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5578 - val_loss: 0.4642\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.61779 to 0.46415, saving model to folds0.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4891 - val_loss: 0.5745\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.46415\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4628 - val_loss: 0.4071\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46415 to 0.40706, saving model to folds0.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4293 - val_loss: 0.4074\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40706\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4141 - val_loss: 0.4197\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.40706\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3981 - val_loss: 0.4394\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40706\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3835 - val_loss: 0.3581\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.40706 to 0.35807, saving model to folds0.hdf5\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3595 - val_loss: 0.3680\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.35807\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3651 - val_loss: 0.3538\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35807 to 0.35384, saving model to folds0.hdf5\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3501 - val_loss: 0.3587\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.35384\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3669 - val_loss: 0.3665\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.35384\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3298 - val_loss: 0.3147\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.35384 to 0.31466, saving model to folds0.hdf5\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3234 - val_loss: 0.3234\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31466\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3072 - val_loss: 0.3306\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31466\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3106 - val_loss: 0.3130\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.31466 to 0.31297, saving model to folds0.hdf5\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2961 - val_loss: 0.3138\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.31297\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3012 - val_loss: 0.2968\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.31297 to 0.29677, saving model to folds0.hdf5\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3020 - val_loss: 0.2773\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29677 to 0.27733, saving model to folds0.hdf5\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2761 - val_loss: 0.2721\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.27733 to 0.27209, saving model to folds0.hdf5\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2716 - val_loss: 0.2686\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.27209 to 0.26856, saving model to folds0.hdf5\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2682 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26856\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2606 - val_loss: 0.2820\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.26856\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.2590 - val_loss: 0.2774\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.26856\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2717 - val_loss: 0.2606\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.26856 to 0.26059, saving model to folds0.hdf5\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2494 - val_loss: 0.2649\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26059\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2448 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26059\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2568 - val_loss: 0.2462\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.26059 to 0.24617, saving model to folds0.hdf5\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2438 - val_loss: 0.2680\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.24617\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2386 - val_loss: 0.2593\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24617\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2361 - val_loss: 0.2575\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24617\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2739 - val_loss: 0.2391\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.24617 to 0.23906, saving model to folds0.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2355 - val_loss: 0.2423\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.23906\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2305 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.23906 to 0.23212, saving model to folds0.hdf5\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2294 - val_loss: 0.2608\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.23212\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2403 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.23212\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2204 - val_loss: 0.2319\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.23212 to 0.23195, saving model to folds0.hdf5\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2237 - val_loss: 0.2365\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23195\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2242 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.23195\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2168 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.23195 to 0.22396, saving model to folds0.hdf5\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2208 - val_loss: 0.2353\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22396\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2287 - val_loss: 0.2329\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22396\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2222 - val_loss: 0.2205\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.22396 to 0.22047, saving model to folds0.hdf5\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2117 - val_loss: 0.2270\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.22047\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2151 - val_loss: 0.2862\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.22047\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2524 - val_loss: 0.2341\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.22047\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2213 - val_loss: 0.2451\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.22047\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2186 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.22047\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2067 - val_loss: 0.2245\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.22047\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2053 - val_loss: 0.2533\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.22047\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2157 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.22047\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2067 - val_loss: 0.2236\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.22047\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2108 - val_loss: 0.2276\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.22047\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1866 - val_loss: 0.2002\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.22047 to 0.20024, saving model to folds0.hdf5\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1775 - val_loss: 0.1994\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.20024 to 0.19938, saving model to folds0.hdf5\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1731 - val_loss: 0.1874\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.19938 to 0.18743, saving model to folds0.hdf5\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1679 - val_loss: 0.1899\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.18743\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1654 - val_loss: 0.1921\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.18743\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1669 - val_loss: 0.1902\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.18743\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1628 - val_loss: 0.2033\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.18743\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1708 - val_loss: 0.1846\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.18743 to 0.18459, saving model to folds0.hdf5\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1614 - val_loss: 0.1873\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.18459\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1639 - val_loss: 0.1972\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.18459\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1650 - val_loss: 0.1882\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.18459\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1650 - val_loss: 0.1912\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18459\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1642 - val_loss: 0.1969\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.18459\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1639 - val_loss: 0.1855\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18459\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1594 - val_loss: 0.1928\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.18459\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1590 - val_loss: 0.1907\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18459\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1608 - val_loss: 0.1834\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.18459 to 0.18344, saving model to folds0.hdf5\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1585 - val_loss: 0.1861\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.18344\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1613 - val_loss: 0.1841\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.18344\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1575 - val_loss: 0.1926\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.18344\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1586 - val_loss: 0.1869\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.18344\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1595 - val_loss: 0.1873\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.18344\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1546 - val_loss: 0.1855\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.18344\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1622 - val_loss: 0.1907\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.18344\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1659 - val_loss: 0.1914\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.18344\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1593 - val_loss: 0.2098\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.18344\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1637 - val_loss: 0.1865\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.18344\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1466 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.18344 to 0.17335, saving model to folds0.hdf5\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1382 - val_loss: 0.1821\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17335\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1407 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17335\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1363 - val_loss: 0.1744\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17335\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1352 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.17335 to 0.17264, saving model to folds0.hdf5\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1339 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.17264 to 0.17196, saving model to folds0.hdf5\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1323 - val_loss: 0.1722\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17196\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1331 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.17196 to 0.17054, saving model to folds0.hdf5\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1322 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17054\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1338 - val_loss: 0.1764\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17054\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1313 - val_loss: 0.1718\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17054\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1307 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17054\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1296 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17054\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1293 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17054\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1298 - val_loss: 0.1744\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17054\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1284 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17054\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1288 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17054\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1289 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.17054\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1235 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.17054 to 0.16885, saving model to folds0.hdf5\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1201 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.16885 to 0.16885, saving model to folds0.hdf5\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1190 - val_loss: 0.1687\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.16885 to 0.16868, saving model to folds0.hdf5\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1188 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.16868\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1187 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.16868\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1180 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.16868\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1176 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.16868 to 0.16757, saving model to folds0.hdf5\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1171 - val_loss: 0.1687\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.16757\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1164 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.16757\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1167 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.16757\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1157 - val_loss: 0.1721\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16757\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1168 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16757\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1161 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16757\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1166 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16757\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1149 - val_loss: 0.1688\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16757\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1145 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16757\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.1148 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16757\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1122 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16757\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1105 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16757\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1097 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.16757 to 0.16751, saving model to folds0.hdf5\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1093 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16751\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1094 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16751\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1090 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16751\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1095 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16751\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1084 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16751\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1083 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16751\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1080 - val_loss: 0.1688\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16751\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1069 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.16751 to 0.16746, saving model to folds0.hdf5\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1057 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16746\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1058 - val_loss: 0.1672\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.16746 to 0.16716, saving model to folds0.hdf5\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1059 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16716\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1055 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16716\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1058 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16716\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1053 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16716\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1053 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16716\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1050 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16716\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1048 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16716\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1049 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16716\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1048 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16716\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1048 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16716\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1042 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16716\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1035 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16716\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1036 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16716\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1032 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16716\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1051 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16716\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1041 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16716\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1036 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16716\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1028 - val_loss: 0.1686\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16716\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1028 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16716\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1028 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16716\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1026 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16716\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1023 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16716\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1024 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16716\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1023 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16716\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1026 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16716\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1021 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16716\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1020 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16716\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1025 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16716\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1023 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16716\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1023 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16716\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1018 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16716\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1018 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16716\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1012 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16716\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1020 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16716\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1014 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16716\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1020 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16716\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 10s 149ms/step - loss: 0.1012 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16716\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1018 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16716\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1015 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16716\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1018 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16716\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1022 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16716\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1017 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16716\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1011 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16716\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1012 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16716\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1017 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16716\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1010 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16716\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1012 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16716\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1013 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16716\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1015 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16716\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1013 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16716\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1013 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16716\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1015 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16716\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1013 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16716\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1013 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16716\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1014 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.16716\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1018 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16716\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1015 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.16716\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1011 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.16716\n",
      "Epoch 190/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1014 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.16716\n",
      "Epoch 191/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1013 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.16716\n",
      "Epoch 00191: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 2 < ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 22:33:58.524710: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 55s 422ms/step - loss: 4.1891 - val_loss: 1.1495\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.14949, saving model to folds1.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 1.0435 - val_loss: 0.7006\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.14949 to 0.70061, saving model to folds1.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.6902 - val_loss: 0.6409\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70061 to 0.64095, saving model to folds1.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.6018 - val_loss: 0.4938\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64095 to 0.49377, saving model to folds1.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5052 - val_loss: 0.4773\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49377 to 0.47728, saving model to folds1.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.4798 - val_loss: 0.4743\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47728 to 0.47429, saving model to folds1.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.4466 - val_loss: 0.4162\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47429 to 0.41622, saving model to folds1.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4335 - val_loss: 0.4085\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41622 to 0.40848, saving model to folds1.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4144 - val_loss: 0.4002\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40848 to 0.40022, saving model to folds1.hdf5\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3873 - val_loss: 0.3690\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.40022 to 0.36897, saving model to folds1.hdf5\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3662 - val_loss: 0.4053\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36897\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3820 - val_loss: 0.3656\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.36897 to 0.36561, saving model to folds1.hdf5\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3438 - val_loss: 0.3483\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36561 to 0.34830, saving model to folds1.hdf5\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.3458 - val_loss: 0.3341\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34830 to 0.33406, saving model to folds1.hdf5\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3390 - val_loss: 0.3340\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33406 to 0.33399, saving model to folds1.hdf5\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3202 - val_loss: 0.3456\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.33399\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3248 - val_loss: 0.3041\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.33399 to 0.30407, saving model to folds1.hdf5\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3089 - val_loss: 0.3090\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.30407\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3001 - val_loss: 0.3181\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.30407\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3099 - val_loss: 0.3077\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.30407\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3070 - val_loss: 0.3053\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.30407\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2852 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.30407 to 0.29195, saving model to folds1.hdf5\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2840 - val_loss: 0.3180\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.29195\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3039 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.29195 to 0.27561, saving model to folds1.hdf5\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2787 - val_loss: 0.2807\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27561\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2723 - val_loss: 0.2984\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.27561\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2777 - val_loss: 0.3119\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.27561\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2721 - val_loss: 0.2573\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.27561 to 0.25732, saving model to folds1.hdf5\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2600 - val_loss: 0.2643\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.25732\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2564 - val_loss: 0.2571\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.25732 to 0.25713, saving model to folds1.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2581 - val_loss: 0.2564\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.25713 to 0.25644, saving model to folds1.hdf5\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2581 - val_loss: 0.2750\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25644\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2562 - val_loss: 0.2646\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.25644\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2510 - val_loss: 0.2502\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.25644 to 0.25022, saving model to folds1.hdf5\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2351 - val_loss: 0.2419\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.25022 to 0.24193, saving model to folds1.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2397 - val_loss: 0.2468\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24193\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2266 - val_loss: 0.2351\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.24193 to 0.23505, saving model to folds1.hdf5\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2280 - val_loss: 0.2355\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.23505\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2300 - val_loss: 0.2665\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.23505\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2457 - val_loss: 0.2248\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.23505 to 0.22480, saving model to folds1.hdf5\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2224 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.22480 to 0.21927, saving model to folds1.hdf5\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2144 - val_loss: 0.2239\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.21927\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2179 - val_loss: 0.2480\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.21927\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2231 - val_loss: 0.2453\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.21927\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2138 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.21927 to 0.21724, saving model to folds1.hdf5\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2103 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.21724\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2078 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.21724\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2699 - val_loss: 0.2601\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.21724\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2393 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21724\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2177 - val_loss: 0.2255\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21724\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2101 - val_loss: 0.2172\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.21724 to 0.21721, saving model to folds1.hdf5\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2061 - val_loss: 0.2152\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.21721 to 0.21515, saving model to folds1.hdf5\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2092 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21515\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2340 - val_loss: 0.2424\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21515\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2178 - val_loss: 0.2127\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.21515 to 0.21266, saving model to folds1.hdf5\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2045 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21266\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2163 - val_loss: 0.2272\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.21266\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2141 - val_loss: 0.2425\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.21266\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2100 - val_loss: 0.2335\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.21266\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2034 - val_loss: 0.2246\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.21266\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 0.2143 - val_loss: 0.2144\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.21266\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2049 - val_loss: 0.2191\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.21266\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1990 - val_loss: 0.2065\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.21266 to 0.20650, saving model to folds1.hdf5\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1897 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20650\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1948 - val_loss: 0.2228\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20650\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1881 - val_loss: 0.1989\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.20650 to 0.19887, saving model to folds1.hdf5\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1820 - val_loss: 0.2357\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.19887\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2032 - val_loss: 0.2129\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.19887\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1925 - val_loss: 0.2026\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.19887\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1953 - val_loss: 0.2072\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.19887\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1905 - val_loss: 0.1995\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.19887\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1801 - val_loss: 0.2211\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.19887\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1863 - val_loss: 0.2100\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.19887\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1905 - val_loss: 0.2016\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.19887\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1767 - val_loss: 0.2138\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.19887\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1859 - val_loss: 0.2199\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.19887\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1692 - val_loss: 0.1886\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.19887 to 0.18856, saving model to folds1.hdf5\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1579 - val_loss: 0.1784\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.18856 to 0.17836, saving model to folds1.hdf5\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1499 - val_loss: 0.1837\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17836\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1507 - val_loss: 0.1816\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17836\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1466 - val_loss: 0.1777\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.17836 to 0.17770, saving model to folds1.hdf5\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1432 - val_loss: 0.1767\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.17770 to 0.17667, saving model to folds1.hdf5\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 10s 149ms/step - loss: 0.1450 - val_loss: 0.1766\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.17667 to 0.17656, saving model to folds1.hdf5\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1432 - val_loss: 0.1762\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.17656 to 0.17621, saving model to folds1.hdf5\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1420 - val_loss: 0.1749\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.17621 to 0.17492, saving model to folds1.hdf5\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1419 - val_loss: 0.1752\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17492\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1404 - val_loss: 0.1796\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17492\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1426 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17492\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1630 - val_loss: 0.1785\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.17492\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1436 - val_loss: 0.1777\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17492\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1414 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.17492 to 0.17272, saving model to folds1.hdf5\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1385 - val_loss: 0.1795\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17272\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1440 - val_loss: 0.1779\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17272\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1413 - val_loss: 0.1769\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17272\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1379 - val_loss: 0.1774\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17272\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1381 - val_loss: 0.1768\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17272\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1367 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.17272 to 0.17195, saving model to folds1.hdf5\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1371 - val_loss: 0.1754\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17195\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1372 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17195\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1355 - val_loss: 0.1748\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17195\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1330 - val_loss: 0.1770\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.17195\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1327 - val_loss: 0.1813\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.17195\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1317 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.17195\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1368 - val_loss: 0.1754\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17195\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1312 - val_loss: 0.1823\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.17195\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1401 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.17195 to 0.17192, saving model to folds1.hdf5\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1380 - val_loss: 0.1795\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17192\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1305 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.17192 to 0.17139, saving model to folds1.hdf5\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1196 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.17139 to 0.16962, saving model to folds1.hdf5\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1179 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.16962 to 0.16810, saving model to folds1.hdf5\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1156 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.16810 to 0.16762, saving model to folds1.hdf5\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1145 - val_loss: 0.1865\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16762\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1250 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16762\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1150 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16762\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1145 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16762\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1135 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16762\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1115 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16762\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1116 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16762\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 10s 149ms/step - loss: 0.1114 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16762\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1114 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16762\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1102 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16762\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1073 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16762\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1048 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.16762 to 0.16747, saving model to folds1.hdf5\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1036 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.16747 to 0.16743, saving model to folds1.hdf5\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1035 - val_loss: 0.1686\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16743\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1033 - val_loss: 0.1667\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.16743 to 0.16665, saving model to folds1.hdf5\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1027 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16665\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1019 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.16665 to 0.16638, saving model to folds1.hdf5\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1016 - val_loss: 0.1658\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.16638 to 0.16579, saving model to folds1.hdf5\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1017 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16579\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1006 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16579\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1009 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16579\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1000 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16579\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1000 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16579\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0999 - val_loss: 0.1669\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16579\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0999 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16579\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0994 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16579\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0986 - val_loss: 0.1668\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16579\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0983 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16579\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0967 - val_loss: 0.1672\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16579\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0951 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16579\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0947 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16579\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0942 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16579\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0939 - val_loss: 0.1670\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16579\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.0940 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16579\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0942 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16579\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0939 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16579\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0948 - val_loss: 0.1686\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16579\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0940 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16579\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0924 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16579\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0919 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16579\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0914 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16579\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0914 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16579\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0914 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16579\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0913 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16579\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0904 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16579\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0906 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16579\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0910 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16579\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0907 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16579\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0901 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16579\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0897 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16579\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0899 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16579\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0899 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16579\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0898 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16579\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0898 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16579\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0898 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16579\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0893 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16579\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0893 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16579\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0893 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16579\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0890 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16579\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0888 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16579\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0889 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16579\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0886 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16579\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0893 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16579\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0887 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16579\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0886 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16579\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0891 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16579\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0886 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16579\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0885 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16579\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0888 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16579\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.0887 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16579\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0886 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16579\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0880 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16579\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0884 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16579\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0881 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16579\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0886 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.16579\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0883 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16579\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0881 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.16579\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0886 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.16579\n",
      "Epoch 00189: early stopping\n",
      "50/50 - 6s\n",
      "--------------- > Fold 3 < ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 23:06:05.460893: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 54s 418ms/step - loss: 4.0966 - val_loss: 1.1229\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.12292, saving model to folds2.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 1.0216 - val_loss: 0.7174\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.12292 to 0.71743, saving model to folds2.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.7058 - val_loss: 0.5822\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71743 to 0.58216, saving model to folds2.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.5930 - val_loss: 0.6860\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.58216\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5660 - val_loss: 0.5189\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.58216 to 0.51894, saving model to folds2.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4816 - val_loss: 0.4934\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51894 to 0.49343, saving model to folds2.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4485 - val_loss: 0.4390\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49343 to 0.43897, saving model to folds2.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4216 - val_loss: 0.4083\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.43897 to 0.40828, saving model to folds2.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4057 - val_loss: 0.3922\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40828 to 0.39223, saving model to folds2.hdf5\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3993 - val_loss: 0.4488\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.39223\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3924 - val_loss: 0.3581\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.39223 to 0.35807, saving model to folds2.hdf5\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 10s 156ms/step - loss: 0.3620 - val_loss: 0.3628\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.35807\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.3504 - val_loss: 0.3592\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.35807\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3640 - val_loss: 0.3346\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35807 to 0.33460, saving model to folds2.hdf5\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 10s 149ms/step - loss: 0.3309 - val_loss: 0.3206\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.33460 to 0.32057, saving model to folds2.hdf5\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3221 - val_loss: 0.3900\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32057\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.3297 - val_loss: 0.3123\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.32057 to 0.31229, saving model to folds2.hdf5\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.3119 - val_loss: 0.3389\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.31229\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.3056 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.31229 to 0.31076, saving model to folds2.hdf5\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2911 - val_loss: 0.3353\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.31076\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2910 - val_loss: 0.3227\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.31076\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2940 - val_loss: 0.3142\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.31076\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2845 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.31076 to 0.28084, saving model to folds2.hdf5\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2797 - val_loss: 0.2895\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28084\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2813 - val_loss: 0.2875\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.28084\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2665 - val_loss: 0.2984\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.28084\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2830 - val_loss: 0.2733\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.28084 to 0.27327, saving model to folds2.hdf5\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2693 - val_loss: 0.2894\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.27327\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2578 - val_loss: 0.2625\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.27327 to 0.26246, saving model to folds2.hdf5\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2603 - val_loss: 0.2551\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26246 to 0.25514, saving model to folds2.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2492 - val_loss: 0.2592\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25514\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2473 - val_loss: 0.2602\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25514\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2644 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.25514\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2463 - val_loss: 0.2832\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.25514\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2492 - val_loss: 0.2596\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.25514\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2393 - val_loss: 0.2552\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.25514\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2327 - val_loss: 0.2440\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.25514 to 0.24404, saving model to folds2.hdf5\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2252 - val_loss: 0.2311\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.24404 to 0.23113, saving model to folds2.hdf5\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2278 - val_loss: 0.2584\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.23113\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2310 - val_loss: 0.2324\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.23113\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2276 - val_loss: 0.2421\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23113\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2260 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.23113\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2193 - val_loss: 0.2492\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.23113\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2176 - val_loss: 0.2173\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.23113 to 0.21732, saving model to folds2.hdf5\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2276 - val_loss: 0.2407\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.21732\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2249 - val_loss: 0.2362\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.21732\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2141 - val_loss: 0.2338\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.21732\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2192 - val_loss: 0.2758\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.21732\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2325 - val_loss: 0.2501\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21732\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2214 - val_loss: 0.2180\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21732\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2059 - val_loss: 0.2394\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21732\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2249 - val_loss: 0.2658\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21732\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2280 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21732\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2197 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21732\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1927 - val_loss: 0.2079\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.21732 to 0.20793, saving model to folds2.hdf5\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1827 - val_loss: 0.2116\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20793\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1826 - val_loss: 0.2025\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.20793 to 0.20246, saving model to folds2.hdf5\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1782 - val_loss: 0.2000\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.20246 to 0.19996, saving model to folds2.hdf5\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1730 - val_loss: 0.2046\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.19996\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1825 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.19996\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1839 - val_loss: 0.1943\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.19996 to 0.19433, saving model to folds2.hdf5\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1698 - val_loss: 0.2001\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.19433\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.1682 - val_loss: 0.1949\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.19433\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1667 - val_loss: 0.1953\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.19433\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1656 - val_loss: 0.1933\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.19433 to 0.19332, saving model to folds2.hdf5\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1665 - val_loss: 0.1891\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.19332 to 0.18912, saving model to folds2.hdf5\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1781 - val_loss: 0.1952\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.18912\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1720 - val_loss: 0.2020\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18912\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1695 - val_loss: 0.1965\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.18912\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1657 - val_loss: 0.1970\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18912\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1693 - val_loss: 0.1962\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.18912\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1630 - val_loss: 0.1878\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.18912 to 0.18779, saving model to folds2.hdf5\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1578 - val_loss: 0.1911\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.18779\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1600 - val_loss: 0.1882\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.18779\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1601 - val_loss: 0.1995\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.18779\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1578 - val_loss: 0.1956\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.18779\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1635 - val_loss: 0.1956\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.18779\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1588 - val_loss: 0.2100\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.18779\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1717 - val_loss: 0.2081\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.18779\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1682 - val_loss: 0.1883\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.18779\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1589 - val_loss: 0.1887\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.18779\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1593 - val_loss: 0.1924\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.18779\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1483 - val_loss: 0.1790\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.18779 to 0.17899, saving model to folds2.hdf5\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1420 - val_loss: 0.1809\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17899\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1479 - val_loss: 0.1794\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17899\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1437 - val_loss: 0.1847\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17899\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1441 - val_loss: 0.1791\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17899\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1414 - val_loss: 0.1757\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.17899 to 0.17574, saving model to folds2.hdf5\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1362 - val_loss: 0.1751\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.17574 to 0.17515, saving model to folds2.hdf5\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1345 - val_loss: 0.1764\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17515\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1334 - val_loss: 0.1772\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17515\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1325 - val_loss: 0.1759\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17515\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1336 - val_loss: 0.1766\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17515\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1321 - val_loss: 0.1752\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17515\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1309 - val_loss: 0.1770\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17515\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1310 - val_loss: 0.1750\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.17515 to 0.17499, saving model to folds2.hdf5\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1308 - val_loss: 0.1754\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17499\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1291 - val_loss: 0.1808\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17499\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1317 - val_loss: 0.1807\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17499\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1353 - val_loss: 0.1798\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17499\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1321 - val_loss: 0.1813\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.17499\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1311 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.17499 to 0.17356, saving model to folds2.hdf5\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1277 - val_loss: 0.1762\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.17356\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1287 - val_loss: 0.1749\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17356\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1278 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.17356 to 0.17280, saving model to folds2.hdf5\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.1249 - val_loss: 0.1743\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.17280\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1268 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17280\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1244 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.17280\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1243 - val_loss: 0.1839\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.17280\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1273 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.17280\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1229 - val_loss: 0.1873\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.17280\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1354 - val_loss: 0.1778\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.17280\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1247 - val_loss: 0.1770\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.17280\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1233 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.17280\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1217 - val_loss: 0.1745\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.17280\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1179 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.17280 to 0.16887, saving model to folds2.hdf5\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1163 - val_loss: 0.1698\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16887\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1134 - val_loss: 0.1788\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16887\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1209 - val_loss: 0.1721\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16887\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1132 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16887\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1119 - val_loss: 0.1718\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16887\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1112 - val_loss: 0.1713\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16887\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1106 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16887\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1108 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16887\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1106 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16887\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1093 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16887\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1075 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16887\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1059 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16887\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1055 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.16887 to 0.16886, saving model to folds2.hdf5\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1048 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16886\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1050 - val_loss: 0.1694\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16886\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1047 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16886\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1039 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16886\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1039 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16886\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1037 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16886\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1034 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16886\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1021 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16886\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1018 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16886\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1013 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16886\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1015 - val_loss: 0.1698\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16886\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1009 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16886\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1012 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16886\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1007 - val_loss: 0.1698\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16886\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1008 - val_loss: 0.1698\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16886\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1003 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16886\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1005 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16886\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1001 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16886\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0993 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16886\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0996 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16886\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0993 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16886\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0990 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16886\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0993 - val_loss: 0.1698\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16886\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0989 - val_loss: 0.1697\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16886\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0988 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16886\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0991 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16886\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0988 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16886\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.0987 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16886\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0982 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16886\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0985 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16886\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0987 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16886\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0981 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16886\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0988 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16886\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0983 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16886\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0981 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16886\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0984 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16886\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0978 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16886\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0979 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16886\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0984 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16886\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0977 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16886\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0978 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16886\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0978 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16886\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0972 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16886\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0972 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16886\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0980 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16886\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0973 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16886\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0975 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16886\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0978 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16886\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0974 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16886\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0978 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16886\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0975 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16886\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0974 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16886\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0973 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16886\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0980 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16886\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0974 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16886\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0974 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16886\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0972 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.16886\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0973 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16886\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0975 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.16886\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.0971 - val_loss: 0.1701\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.16886\n",
      "Epoch 00189: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 4 < ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-04 23:37:54.452645: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 55s 440ms/step - loss: 3.9014 - val_loss: 1.1455\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.14545, saving model to folds3.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 1.0822 - val_loss: 0.7326\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.14545 to 0.73264, saving model to folds3.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.7147 - val_loss: 0.6415\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73264 to 0.64152, saving model to folds3.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.6373 - val_loss: 0.5306\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.64152 to 0.53062, saving model to folds3.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.5809 - val_loss: 0.4990\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53062 to 0.49903, saving model to folds3.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5033 - val_loss: 0.4619\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49903 to 0.46188, saving model to folds3.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4853 - val_loss: 0.4219\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46188 to 0.42188, saving model to folds3.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4269 - val_loss: 0.4178\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42188 to 0.41782, saving model to folds3.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4279 - val_loss: 0.4371\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41782\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.4084 - val_loss: 0.3845\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.41782 to 0.38447, saving model to folds3.hdf5\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3830 - val_loss: 0.3555\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.38447 to 0.35551, saving model to folds3.hdf5\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3735 - val_loss: 0.3773\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.35551\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3636 - val_loss: 0.4181\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.35551\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3804 - val_loss: 0.3725\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.35551\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3502 - val_loss: 0.3658\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.35551\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3543 - val_loss: 0.4046\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.35551\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3392 - val_loss: 0.3320\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.35551 to 0.33202, saving model to folds3.hdf5\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3131 - val_loss: 0.3235\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.33202 to 0.32351, saving model to folds3.hdf5\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.3064 - val_loss: 0.3330\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.32351\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3252 - val_loss: 0.3350\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.32351\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3257 - val_loss: 0.3171\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.32351 to 0.31710, saving model to folds3.hdf5\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3028 - val_loss: 0.3225\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.31710\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3176 - val_loss: 0.3168\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.31710 to 0.31679, saving model to folds3.hdf5\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3069 - val_loss: 0.3322\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.31679\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3045 - val_loss: 0.3094\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.31679 to 0.30943, saving model to folds3.hdf5\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2811 - val_loss: 0.2700\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.30943 to 0.27004, saving model to folds3.hdf5\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2761 - val_loss: 0.2690\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.27004 to 0.26897, saving model to folds3.hdf5\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2662 - val_loss: 0.3033\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.26897\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2784 - val_loss: 0.2877\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26897\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2747 - val_loss: 0.2586\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26897 to 0.25858, saving model to folds3.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2597 - val_loss: 0.2697\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25858\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2460 - val_loss: 0.2756\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25858\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2520 - val_loss: 0.2690\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.25858\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2598 - val_loss: 0.2572\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.25858 to 0.25720, saving model to folds3.hdf5\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2590 - val_loss: 0.2501\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.25720 to 0.25012, saving model to folds3.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2512 - val_loss: 0.2454\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.25012 to 0.24536, saving model to folds3.hdf5\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2489 - val_loss: 0.2429\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.24536 to 0.24291, saving model to folds3.hdf5\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2332 - val_loss: 0.2515\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24291\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.2334 - val_loss: 0.2550\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.24291\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2338 - val_loss: 0.2563\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.24291\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2247 - val_loss: 0.2261\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.24291 to 0.22609, saving model to folds3.hdf5\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2215 - val_loss: 0.2317\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.22609\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2235 - val_loss: 0.2495\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.22609\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2268 - val_loss: 0.2390\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22609\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2360 - val_loss: 0.2304\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22609\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2294 - val_loss: 0.2610\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.22609\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2332 - val_loss: 0.2359\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.22609\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2201 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.22609 to 0.21929, saving model to folds3.hdf5\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2221 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21929\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.2209 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21929\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2103 - val_loss: 0.2306\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21929\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2119 - val_loss: 0.2633\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21929\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2288 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21929\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2144 - val_loss: 0.2203\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21929\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2959 - val_loss: 0.3059\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21929\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2715 - val_loss: 0.2453\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21929\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2352 - val_loss: 0.2506\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.21929\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2283 - val_loss: 0.2397\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.21929\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2041 - val_loss: 0.2008\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.21929 to 0.20078, saving model to folds3.hdf5\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1849 - val_loss: 0.1975\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.20078 to 0.19746, saving model to folds3.hdf5\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1797 - val_loss: 0.1950\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.19746 to 0.19501, saving model to folds3.hdf5\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1820 - val_loss: 0.1944\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.19501 to 0.19439, saving model to folds3.hdf5\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1783 - val_loss: 0.1935\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.19439 to 0.19347, saving model to folds3.hdf5\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1751 - val_loss: 0.1936\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.19347\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 10s 157ms/step - loss: 0.1735 - val_loss: 0.1891\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.19347 to 0.18906, saving model to folds3.hdf5\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1711 - val_loss: 0.1910\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.18906\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1698 - val_loss: 0.1946\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.18906\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.1695 - val_loss: 0.2003\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18906\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1802 - val_loss: 0.1894\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.18906\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1677 - val_loss: 0.1897\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18906\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1686 - val_loss: 0.1890\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.18906 to 0.18902, saving model to folds3.hdf5\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1690 - val_loss: 0.1938\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18902\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1707 - val_loss: 0.1895\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.18902\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1678 - val_loss: 0.1979\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.18902\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1667 - val_loss: 0.1916\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.18902\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1623 - val_loss: 0.1790\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.18902 to 0.17902, saving model to folds3.hdf5\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1510 - val_loss: 0.1777\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.17902 to 0.17768, saving model to folds3.hdf5\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1500 - val_loss: 0.1759\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.17768 to 0.17587, saving model to folds3.hdf5\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1485 - val_loss: 0.1754\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.17587 to 0.17540, saving model to folds3.hdf5\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1475 - val_loss: 0.1761\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17540\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1464 - val_loss: 0.1759\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17540\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1477 - val_loss: 0.1833\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.17540\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1478 - val_loss: 0.1747\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.17540 to 0.17470, saving model to folds3.hdf5\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1461 - val_loss: 0.1761\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17470\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1460 - val_loss: 0.1787\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17470\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1471 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.17470 to 0.17405, saving model to folds3.hdf5\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1437 - val_loss: 0.1756\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17405\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1432 - val_loss: 0.1743\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17405\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1424 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.17405 to 0.17360, saving model to folds3.hdf5\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1458 - val_loss: 0.1748\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17360\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1427 - val_loss: 0.1751\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17360\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1438 - val_loss: 0.1744\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17360\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1405 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.17360 to 0.17323, saving model to folds3.hdf5\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1396 - val_loss: 0.1752\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17323\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1414 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.17323 to 0.17264, saving model to folds3.hdf5\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1398 - val_loss: 0.1819\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17264\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1485 - val_loss: 0.1761\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17264\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1398 - val_loss: 0.1907\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17264\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1465 - val_loss: 0.1836\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17264\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1452 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17264\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1391 - val_loss: 0.1751\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.17264\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1380 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.17264 to 0.17195, saving model to folds3.hdf5\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1370 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.17195\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1352 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17195\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1359 - val_loss: 0.1715\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.17195 to 0.17153, saving model to folds3.hdf5\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1349 - val_loss: 0.1750\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.17153\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1355 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17153\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1325 - val_loss: 0.1755\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.17153\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1344 - val_loss: 0.1697\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.17153 to 0.16972, saving model to folds3.hdf5\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1316 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.16972\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1296 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.16972 to 0.16908, saving model to folds3.hdf5\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1310 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16908\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1308 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16908\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1312 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16908\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1289 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16908\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1320 - val_loss: 0.1697\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16908\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1296 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16908\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1287 - val_loss: 0.1729\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16908\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1315 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16908\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.1316 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16908\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1301 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16908\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1234 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.16908 to 0.16759, saving model to folds3.hdf5\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1189 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16759\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1187 - val_loss: 0.1668\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.16759 to 0.16678, saving model to folds3.hdf5\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1175 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.16678 to 0.16621, saving model to folds3.hdf5\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.1164 - val_loss: 0.1669\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16621\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1172 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16621\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1164 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16621\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1163 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16621\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1159 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16621\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1149 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16621\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1153 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.16621 to 0.16593, saving model to folds3.hdf5\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1145 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16593\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1143 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16593\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1137 - val_loss: 0.1658\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.16593 to 0.16582, saving model to folds3.hdf5\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1138 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16582\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1134 - val_loss: 0.1672\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16582\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1139 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16582\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1142 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16582\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1132 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16582\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1127 - val_loss: 0.1653\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.16582 to 0.16528, saving model to folds3.hdf5\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1127 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16528\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1125 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16528\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1134 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16528\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1123 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16528\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1120 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16528\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1109 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16528\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1106 - val_loss: 0.1656\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16528\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1097 - val_loss: 0.1656\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16528\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1095 - val_loss: 0.1668\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16528\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1095 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16528\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1086 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16528\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1048 - val_loss: 0.1651\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.16528 to 0.16510, saving model to folds3.hdf5\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1047 - val_loss: 0.1657\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16510\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1042 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16510\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1041 - val_loss: 0.1654\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16510\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1032 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16510\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1031 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16510\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1040 - val_loss: 0.1655\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16510\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1029 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16510\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1032 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16510\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1029 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16510\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1024 - val_loss: 0.1654\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16510\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1007 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16510\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1002 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16510\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.1003 - val_loss: 0.1658\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16510\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1000 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16510\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1000 - val_loss: 0.1655\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16510\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1001 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16510\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0998 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16510\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0995 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16510\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0994 - val_loss: 0.1667\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16510\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0994 - val_loss: 0.1656\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16510\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0989 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16510\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0980 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16510\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0980 - val_loss: 0.1658\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16510\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0985 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16510\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0981 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16510\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0976 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16510\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0981 - val_loss: 0.1657\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16510\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0981 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16510\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0977 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16510\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0979 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16510\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0974 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16510\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0973 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16510\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0976 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.16510\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0972 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16510\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0973 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.16510\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0972 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.16510\n",
      "Epoch 190/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.0975 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.16510\n",
      "Epoch 191/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0971 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.16510\n",
      "Epoch 192/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0967 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.16510\n",
      "Epoch 193/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0972 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.16510\n",
      "Epoch 194/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0965 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.16510\n",
      "Epoch 195/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0970 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.16510\n",
      "Epoch 196/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.16510\n",
      "Epoch 197/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0966 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.16510\n",
      "Epoch 198/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.16510\n",
      "Epoch 199/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0967 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.16510\n",
      "Epoch 200/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.16510\n",
      "Epoch 201/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0970 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.16510\n",
      "Epoch 202/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0967 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.16510\n",
      "Epoch 203/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0967 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.16510\n",
      "Epoch 204/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0964 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.16510\n",
      "Epoch 205/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0968 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.16510\n",
      "Epoch 206/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.16510\n",
      "Epoch 207/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0971 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.16510\n",
      "Epoch 208/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0966 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.16510\n",
      "Epoch 209/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.0965 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.16510\n",
      "Epoch 210/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0969 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.16510\n",
      "Epoch 211/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0967 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.16510\n",
      "Epoch 212/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0969 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.16510\n",
      "Epoch 213/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0961 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.16510\n",
      "Epoch 00213: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 5 < ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-05 00:14:04.352571: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1086480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 56s 438ms/step - loss: 3.8125 - val_loss: 1.5087\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50871, saving model to folds4.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 1.1345 - val_loss: 0.7569\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.50871 to 0.75686, saving model to folds4.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.7290 - val_loss: 0.6137\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75686 to 0.61370, saving model to folds4.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.6058 - val_loss: 0.5705\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61370 to 0.57053, saving model to folds4.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5502 - val_loss: 0.5561\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57053 to 0.55607, saving model to folds4.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5039 - val_loss: 0.4671\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55607 to 0.46708, saving model to folds4.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4538 - val_loss: 0.4155\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46708 to 0.41550, saving model to folds4.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4289 - val_loss: 0.4223\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41550\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4099 - val_loss: 0.3835\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41550 to 0.38350, saving model to folds4.hdf5\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3804 - val_loss: 0.3778\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38350 to 0.37778, saving model to folds4.hdf5\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3676 - val_loss: 0.3733\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.37778 to 0.37334, saving model to folds4.hdf5\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3693 - val_loss: 0.3908\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.37334\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3652 - val_loss: 0.3363\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.37334 to 0.33627, saving model to folds4.hdf5\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3348 - val_loss: 0.3451\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33627\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3464 - val_loss: 0.3394\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33627\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3255 - val_loss: 0.3186\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33627 to 0.31857, saving model to folds4.hdf5\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3132 - val_loss: 0.3047\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.31857 to 0.30466, saving model to folds4.hdf5\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2978 - val_loss: 0.3033\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.30466 to 0.30326, saving model to folds4.hdf5\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3030 - val_loss: 0.3109\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.30326\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2880 - val_loss: 0.2933\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.30326 to 0.29329, saving model to folds4.hdf5\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2932 - val_loss: 0.2871\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.29329 to 0.28712, saving model to folds4.hdf5\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2960 - val_loss: 0.2830\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.28712 to 0.28300, saving model to folds4.hdf5\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2807 - val_loss: 0.2908\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28300\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2782 - val_loss: 0.2859\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28300\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.2765 - val_loss: 0.2830\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.28300 to 0.28298, saving model to folds4.hdf5\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2655 - val_loss: 0.2897\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.28298\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2679 - val_loss: 0.2639\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.28298 to 0.26390, saving model to folds4.hdf5\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2513 - val_loss: 0.2729\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.26390\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2610 - val_loss: 0.2617\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.26390 to 0.26174, saving model to folds4.hdf5\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2480 - val_loss: 0.2481\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26174 to 0.24811, saving model to folds4.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.2424 - val_loss: 0.2527\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.24811\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2381 - val_loss: 0.2473\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.24811 to 0.24726, saving model to folds4.hdf5\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2280 - val_loss: 0.2578\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24726\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2430 - val_loss: 0.2402\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.24726 to 0.24018, saving model to folds4.hdf5\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2448 - val_loss: 0.2482\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24018\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2376 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24018\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2270 - val_loss: 0.2590\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.24018\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2223 - val_loss: 0.2508\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24018\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2294 - val_loss: 0.2491\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.24018\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2324 - val_loss: 0.2344\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.24018 to 0.23435, saving model to folds4.hdf5\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2190 - val_loss: 0.2677\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23435\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2187 - val_loss: 0.2391\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.23435\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2199 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.23435 to 0.22124, saving model to folds4.hdf5\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2139 - val_loss: 0.2222\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22124\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2123 - val_loss: 0.2427\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22124\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2134 - val_loss: 0.2225\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.22124\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2016 - val_loss: 0.2177\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.22124 to 0.21765, saving model to folds4.hdf5\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2069 - val_loss: 0.2350\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.21765\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2143 - val_loss: 0.2295\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21765\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2066 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21765\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2070 - val_loss: 0.2168\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.21765 to 0.21676, saving model to folds4.hdf5\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2102 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21676\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2076 - val_loss: 0.2167\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.21676 to 0.21672, saving model to folds4.hdf5\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2002 - val_loss: 0.2202\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21672\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1991 - val_loss: 0.2289\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21672\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1936 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21672\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1975 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.21672\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2024 - val_loss: 0.2247\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.21672\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2073 - val_loss: 0.2362\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.21672\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2094 - val_loss: 0.2368\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.21672\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2059 - val_loss: 0.2668\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.21672\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2048 - val_loss: 0.1961\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.21672 to 0.19608, saving model to folds4.hdf5\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1733 - val_loss: 0.1920\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.19608 to 0.19195, saving model to folds4.hdf5\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1681 - val_loss: 0.1915\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.19195 to 0.19152, saving model to folds4.hdf5\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1634 - val_loss: 0.1899\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.19152 to 0.18993, saving model to folds4.hdf5\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1602 - val_loss: 0.1868\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.18993 to 0.18681, saving model to folds4.hdf5\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1622 - val_loss: 0.1876\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.18681\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.1600 - val_loss: 0.1917\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18681\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1581 - val_loss: 0.1836\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.18681 to 0.18357, saving model to folds4.hdf5\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1535 - val_loss: 0.1858\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18357\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1529 - val_loss: 0.1818\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.18357 to 0.18177, saving model to folds4.hdf5\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1524 - val_loss: 0.1851\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18177\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1514 - val_loss: 0.1837\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.18177\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1484 - val_loss: 0.1798\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.18177 to 0.17977, saving model to folds4.hdf5\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1486 - val_loss: 0.1783\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.17977 to 0.17828, saving model to folds4.hdf5\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1472 - val_loss: 0.1851\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.17828\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1489 - val_loss: 0.1935\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17828\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1512 - val_loss: 0.1960\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.17828\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1537 - val_loss: 0.1898\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17828\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1529 - val_loss: 0.1931\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17828\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1528 - val_loss: 0.1932\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17828\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1496 - val_loss: 0.1841\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.17828\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1488 - val_loss: 0.1875\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.17828\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1492 - val_loss: 0.1869\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17828\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1498 - val_loss: 0.1866\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17828\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1414 - val_loss: 0.1722\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.17828 to 0.17216, saving model to folds4.hdf5\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1315 - val_loss: 0.1712\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.17216 to 0.17123, saving model to folds4.hdf5\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1294 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.17123 to 0.17042, saving model to folds4.hdf5\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1288 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.17042\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1294 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17042\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1278 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17042\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1265 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17042\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1268 - val_loss: 0.1712\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17042\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1255 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.17042 to 0.17010, saving model to folds4.hdf5\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1252 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17010\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1258 - val_loss: 0.1697\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.17010 to 0.16967, saving model to folds4.hdf5\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1242 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.16967\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1238 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.16967 to 0.16931, saving model to folds4.hdf5\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1232 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.16931\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1231 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.16931\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1224 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.16931\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1240 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.16931\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1229 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.16931 to 0.16931, saving model to folds4.hdf5\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1212 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.16931 to 0.16891, saving model to folds4.hdf5\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1212 - val_loss: 0.1698\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.16891\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1208 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.16891\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1203 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.16891\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1208 - val_loss: 0.1788\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.16891\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1217 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.16891\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1221 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.16891\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1235 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.16891\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1196 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16891\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 140ms/step - loss: 0.1195 - val_loss: 0.1786\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16891\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1244 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16891\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.1150 - val_loss: 0.1694\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16891\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1106 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.16891 to 0.16769, saving model to folds4.hdf5\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1091 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16769\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1083 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16769\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1079 - val_loss: 0.1688\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16769\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1077 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16769\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1078 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16769\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1068 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16769\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1066 - val_loss: 0.1669\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.16769 to 0.16695, saving model to folds4.hdf5\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1061 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16695\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1054 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16695\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1053 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16695\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1052 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16695\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1054 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16695\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1050 - val_loss: 0.1669\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.16695 to 0.16693, saving model to folds4.hdf5\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1049 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16693\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1044 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16693\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1038 - val_loss: 0.1670\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16693\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1037 - val_loss: 0.1690\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16693\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1011 - val_loss: 0.1670\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16693\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0989 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16693\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0989 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16693\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0987 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16693\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0982 - val_loss: 0.1672\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16693\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0988 - val_loss: 0.1668\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.16693 to 0.16681, saving model to folds4.hdf5\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0979 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16681\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0979 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16681\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0974 - val_loss: 0.1687\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16681\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0975 - val_loss: 0.1667\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.16681 to 0.16668, saving model to folds4.hdf5\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16668\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0974 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16668\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1683\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16668\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0968 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16668\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0962 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16668\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.0965 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16668\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0961 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16668\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0958 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16668\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0958 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16668\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0953 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16668\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 10s 154ms/step - loss: 0.0942 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16668\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0931 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16668\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0930 - val_loss: 0.1674\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16668\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0930 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16668\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0929 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16668\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0925 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16668\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0921 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16668\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0928 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16668\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0924 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16668\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0918 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00163: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16668\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0915 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16668\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0916 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16668\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0911 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16668\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0913 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16668\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0909 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16668\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0909 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16668\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0904 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16668\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0909 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16668\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0908 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16668\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0907 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16668\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0907 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16668\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0903 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16668\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0904 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16668\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0902 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16668\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0902 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16668\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0898 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16668\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0901 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16668\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 0.0902 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16668\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0899 - val_loss: 0.1676\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16668\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0898 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00183: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16668\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0901 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16668\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0899 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16668\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0902 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.16668\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0900 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16668\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0894 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.16668\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0898 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.16668\n",
      "Epoch 190/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0896 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.16668\n",
      "Epoch 191/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0897 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.16668\n",
      "Epoch 192/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0899 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.16668\n",
      "Epoch 193/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0901 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.16668\n",
      "Epoch 194/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0894 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.16668\n",
      "Epoch 195/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0896 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.16668\n",
      "Epoch 196/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0896 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.16668\n",
      "Epoch 197/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0897 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.16668\n",
      "Epoch 198/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0896 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.16668\n",
      "Epoch 199/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0896 - val_loss: 0.1680\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.16668\n",
      "Epoch 200/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0899 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.16668\n",
      "Epoch 201/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0894 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.16668\n",
      "Epoch 202/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0898 - val_loss: 0.1679\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.16668\n",
      "Epoch 203/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0896 - val_loss: 0.1678\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.16668\n",
      "Epoch 00203: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 6 < ---------------\n",
      "Epoch 1/300\n",
      "67/67 [==============================] - 55s 430ms/step - loss: 4.2261 - val_loss: 1.2275\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.22752, saving model to folds5.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 10s 149ms/step - loss: 1.0642 - val_loss: 0.6961\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.22752 to 0.69611, saving model to folds5.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.7157 - val_loss: 0.6814\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69611 to 0.68138, saving model to folds5.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.6064 - val_loss: 0.5205\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68138 to 0.52055, saving model to folds5.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5180 - val_loss: 0.5000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52055 to 0.50001, saving model to folds5.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.4690 - val_loss: 0.4919\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.50001 to 0.49192, saving model to folds5.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.4619 - val_loss: 0.4140\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49192 to 0.41400, saving model to folds5.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.4133 - val_loss: 0.3851\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41400 to 0.38509, saving model to folds5.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3912 - val_loss: 0.3903\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.38509\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4069 - val_loss: 0.3634\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.38509 to 0.36336, saving model to folds5.hdf5\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3767 - val_loss: 0.3858\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36336\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3603 - val_loss: 0.3701\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.36336\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3545 - val_loss: 0.3386\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.36336 to 0.33857, saving model to folds5.hdf5\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3335 - val_loss: 0.3213\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.33857 to 0.32127, saving model to folds5.hdf5\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.3151 - val_loss: 0.3108\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.32127 to 0.31081, saving model to folds5.hdf5\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3156 - val_loss: 0.3376\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.31081\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3097 - val_loss: 0.3236\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31081\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3147 - val_loss: 0.3029\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.31081 to 0.30292, saving model to folds5.hdf5\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2855 - val_loss: 0.2815\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.30292 to 0.28145, saving model to folds5.hdf5\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2886 - val_loss: 0.3062\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.28145\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2880 - val_loss: 0.3184\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.28145\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2928 - val_loss: 0.3008\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.28145\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2744 - val_loss: 0.2807\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.28145 to 0.28073, saving model to folds5.hdf5\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2699 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.28073 to 0.26398, saving model to folds5.hdf5\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2524 - val_loss: 0.3030\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26398\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3379 - val_loss: 0.3033\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.26398\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2728 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.26398\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2680 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.26398\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2472 - val_loss: 0.2656\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26398\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2450 - val_loss: 0.2560\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.26398 to 0.25595, saving model to folds5.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2461 - val_loss: 0.2640\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25595\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2341 - val_loss: 0.2793\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.25595\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2425 - val_loss: 0.2519\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.25595 to 0.25186, saving model to folds5.hdf5\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2252 - val_loss: 0.2424\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.25186 to 0.24242, saving model to folds5.hdf5\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2260 - val_loss: 0.2442\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24242\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2225 - val_loss: 0.2591\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24242\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2248 - val_loss: 0.2495\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.24242\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2447 - val_loss: 0.2435\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24242\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2255 - val_loss: 0.2281\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.24242 to 0.22811, saving model to folds5.hdf5\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2093 - val_loss: 0.2506\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.22811\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2224 - val_loss: 0.2551\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.22811\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2224 - val_loss: 0.2405\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.22811\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2137 - val_loss: 0.2345\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.22811\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2167 - val_loss: 0.2436\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22811\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2191 - val_loss: 0.2414\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22811\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2112 - val_loss: 0.2339\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.22811\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2079 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.22811\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2027 - val_loss: 0.2204\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.22811 to 0.22036, saving model to folds5.hdf5\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2015 - val_loss: 0.2159\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.22036 to 0.21589, saving model to folds5.hdf5\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1980 - val_loss: 0.2132\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.21589 to 0.21315, saving model to folds5.hdf5\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2042 - val_loss: 0.2347\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21315\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2113 - val_loss: 0.2405\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21315\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2074 - val_loss: 0.2198\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21315\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 0.2021 - val_loss: 0.2405\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21315\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2030 - val_loss: 0.2124\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.21315 to 0.21239, saving model to folds5.hdf5\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1972 - val_loss: 0.2151\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21239\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1882 - val_loss: 0.2070\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.21239 to 0.20702, saving model to folds5.hdf5\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1927 - val_loss: 0.2075\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20702\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1912 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20702\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1937 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20702\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1973 - val_loss: 0.2367\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20702\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2094 - val_loss: 0.2233\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20702\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1996 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20702\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.2107 - val_loss: 0.2249\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20702\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1956 - val_loss: 0.2145\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20702\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1874 - val_loss: 0.2120\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20702\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1811 - val_loss: 0.2053\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.20702 to 0.20527, saving model to folds5.hdf5\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 10s 156ms/step - loss: 0.1820 - val_loss: 0.2258\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20527\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1897 - val_loss: 0.2018\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.20527 to 0.20183, saving model to folds5.hdf5\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1769 - val_loss: 0.2036\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20183\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1804 - val_loss: 0.2036\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20183\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1721 - val_loss: 0.1977\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.20183 to 0.19773, saving model to folds5.hdf5\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1702 - val_loss: 0.2019\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.19773\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1714 - val_loss: 0.2021\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.19773\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1730 - val_loss: 0.1947\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.19773 to 0.19467, saving model to folds5.hdf5\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1748 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.19467\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1796 - val_loss: 0.2015\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.19467\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1699 - val_loss: 0.1965\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.19467\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1677 - val_loss: 0.1981\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.19467\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1677 - val_loss: 0.2016\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.19467\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1672 - val_loss: 0.2049\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.19467\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1639 - val_loss: 0.2037\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.19467\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1638 - val_loss: 0.2106\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.19467\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1717 - val_loss: 0.2031\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.19467\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1603 - val_loss: 0.1972\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.19467\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1457 - val_loss: 0.1809\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.19467 to 0.18091, saving model to folds5.hdf5\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1364 - val_loss: 0.1812\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.18091\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1366 - val_loss: 0.1806\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.18091 to 0.18065, saving model to folds5.hdf5\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1321 - val_loss: 0.1808\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.18065\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1344 - val_loss: 0.1800\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.18065 to 0.18003, saving model to folds5.hdf5\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1324 - val_loss: 0.1767\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.18003 to 0.17669, saving model to folds5.hdf5\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1288 - val_loss: 0.1833\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17669\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1334 - val_loss: 0.1771\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17669\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1293 - val_loss: 0.1768\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17669\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1262 - val_loss: 0.1811\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17669\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1276 - val_loss: 0.1827\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17669\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1268 - val_loss: 0.1766\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.17669 to 0.17662, saving model to folds5.hdf5\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1266 - val_loss: 0.1767\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17662\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1258 - val_loss: 0.1768\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17662\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1267 - val_loss: 0.1887\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17662\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1366 - val_loss: 0.1810\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.17662\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1218 - val_loss: 0.1749\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.17662 to 0.17494, saving model to folds5.hdf5\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1148 - val_loss: 0.1757\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.17494\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1134 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.17494 to 0.17341, saving model to folds5.hdf5\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1108 - val_loss: 0.1721\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.17341 to 0.17209, saving model to folds5.hdf5\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1108 - val_loss: 0.1725\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.17209\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1101 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17209\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1100 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.17209\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1091 - val_loss: 0.1758\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.17209\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1088 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.17209\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1083 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.17209\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1081 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.17209\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1069 - val_loss: 0.1750\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.17209\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1070 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.17209\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1072 - val_loss: 0.1766\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.17209\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1032 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.17209\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1002 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.17209\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0998 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.17209\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0986 - val_loss: 0.1724\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.17209\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0988 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.17209\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0983 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.17209\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0983 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.17209\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0978 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.17209\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0971 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.17209\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0969 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.17209\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0951 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.17209\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0939 - val_loss: 0.1725\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.17209\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0936 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.17209\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0932 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.17209\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 10s 156ms/step - loss: 0.0934 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.17209\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.0931 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.17209\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0927 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.17209\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0923 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.17209\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0924 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.17209\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0920 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.17209\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0910 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.17209\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0910 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.17209\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0904 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.17209\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.0901 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.17209\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0901 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.17209\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0897 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.17209\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0901 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.17209\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0901 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.17209\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.0892 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.17209\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0892 - val_loss: 0.1743\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.17209\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0889 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.17209\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0888 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.17209\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0891 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.17209\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0884 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.17209\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0888 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.17209\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0886 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.17209\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0884 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.17209\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0882 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.17209\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0884 - val_loss: 0.1743\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.17209\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0881 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.17209\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0881 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.17209\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0880 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.17209\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0876 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.17209\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0876 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.17209\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0878 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.17209\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0875 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.17209\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0876 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.17209\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0877 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.17209\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0880 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.17209\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0876 - val_loss: 0.1743\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.17209\n",
      "Epoch 00165: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 7 < ---------------\n",
      "Epoch 1/300\n",
      "67/67 [==============================] - 56s 442ms/step - loss: 3.9040 - val_loss: 1.1393\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.13925, saving model to folds6.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 1.0465 - val_loss: 0.8599\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.13925 to 0.85992, saving model to folds6.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.7736 - val_loss: 0.6550\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.85992 to 0.65503, saving model to folds6.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5869 - val_loss: 0.6840\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.65503\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5550 - val_loss: 0.4530\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65503 to 0.45299, saving model to folds6.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.4921 - val_loss: 0.4189\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45299 to 0.41885, saving model to folds6.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4300 - val_loss: 0.5138\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41885\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.4498 - val_loss: 0.3853\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41885 to 0.38528, saving model to folds6.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3921 - val_loss: 0.3686\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38528 to 0.36861, saving model to folds6.hdf5\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 0.3731 - val_loss: 0.4073\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36861\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3724 - val_loss: 0.3515\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.36861 to 0.35146, saving model to folds6.hdf5\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3493 - val_loss: 0.3510\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.35146 to 0.35101, saving model to folds6.hdf5\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3450 - val_loss: 0.3455\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.35101 to 0.34549, saving model to folds6.hdf5\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3443 - val_loss: 0.3304\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.34549 to 0.33044, saving model to folds6.hdf5\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3284 - val_loss: 0.3311\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33044\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3230 - val_loss: 0.3138\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33044 to 0.31383, saving model to folds6.hdf5\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3157 - val_loss: 0.3826\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.31383\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3184 - val_loss: 0.2881\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.31383 to 0.28808, saving model to folds6.hdf5\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2867 - val_loss: 0.3894\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.28808\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 0.3448 - val_loss: 0.3333\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.28808\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.3135 - val_loss: 0.3155\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.28808\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2900 - val_loss: 0.2819\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.28808 to 0.28188, saving model to folds6.hdf5\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2752 - val_loss: 0.2766\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.28188 to 0.27655, saving model to folds6.hdf5\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2716 - val_loss: 0.3000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.27655\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2730 - val_loss: 0.2538\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.27655 to 0.25381, saving model to folds6.hdf5\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2491 - val_loss: 0.2583\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.25381\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2531 - val_loss: 0.2536\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.25381 to 0.25362, saving model to folds6.hdf5\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2523 - val_loss: 0.2814\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.25362\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2511 - val_loss: 0.2538\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.25362\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2395 - val_loss: 0.2638\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.25362\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2349 - val_loss: 0.2992\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.25362\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2443 - val_loss: 0.2387\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.25362 to 0.23867, saving model to folds6.hdf5\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2354 - val_loss: 0.2410\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.23867\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2255 - val_loss: 0.3117\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.23867\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2755 - val_loss: 0.2357\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.23867 to 0.23566, saving model to folds6.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2282 - val_loss: 0.2307\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.23566 to 0.23071, saving model to folds6.hdf5\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2198 - val_loss: 0.2488\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.23071\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2213 - val_loss: 0.2443\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.23071\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2203 - val_loss: 0.2213\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.23071 to 0.22131, saving model to folds6.hdf5\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2138 - val_loss: 0.2232\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.22131\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2118 - val_loss: 0.2254\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.22131\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2121 - val_loss: 0.2243\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.22131\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2279 - val_loss: 0.2283\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.22131\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2117 - val_loss: 0.2294\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22131\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2144 - val_loss: 0.2290\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22131\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2043 - val_loss: 0.2169\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.22131 to 0.21689, saving model to folds6.hdf5\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2100 - val_loss: 0.2321\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.21689\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2060 - val_loss: 0.2124\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.21689 to 0.21239, saving model to folds6.hdf5\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2000 - val_loss: 0.2349\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21239\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2026 - val_loss: 0.2144\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21239\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1972 - val_loss: 0.2081\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.21239 to 0.20806, saving model to folds6.hdf5\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.1929 - val_loss: 0.2404\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.20806\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.2058 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.20806\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2067 - val_loss: 0.2240\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20806\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1990 - val_loss: 0.2134\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20806\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1974 - val_loss: 0.2061\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.20806 to 0.20610, saving model to folds6.hdf5\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1862 - val_loss: 0.2241\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20610\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1921 - val_loss: 0.2102\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20610\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1912 - val_loss: 0.2127\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20610\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1960 - val_loss: 0.2044\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.20610 to 0.20438, saving model to folds6.hdf5\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1841 - val_loss: 0.2151\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20438\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1953 - val_loss: 0.2078\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20438\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1863 - val_loss: 0.2050\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20438\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1818 - val_loss: 0.2208\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20438\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1927 - val_loss: 0.2095\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20438\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1857 - val_loss: 0.2096\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20438\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1845 - val_loss: 0.2056\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20438\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1781 - val_loss: 0.2415\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20438\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1821 - val_loss: 0.2079\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20438\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1809 - val_loss: 0.2080\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.20438\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1617 - val_loss: 0.1818\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.20438 to 0.18181, saving model to folds6.hdf5\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1483 - val_loss: 0.1816\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.18181 to 0.18162, saving model to folds6.hdf5\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1451 - val_loss: 0.1867\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.18162\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1456 - val_loss: 0.1808\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.18162 to 0.18080, saving model to folds6.hdf5\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1440 - val_loss: 0.1801\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.18080 to 0.18011, saving model to folds6.hdf5\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1407 - val_loss: 0.1783\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.18011 to 0.17833, saving model to folds6.hdf5\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1413 - val_loss: 0.1797\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17833\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1418 - val_loss: 0.1857\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.17833\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1395 - val_loss: 0.1865\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17833\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1430 - val_loss: 0.1843\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17833\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 10s 153ms/step - loss: 0.1385 - val_loss: 0.1808\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17833\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1397 - val_loss: 0.1829\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.17833\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1374 - val_loss: 0.1813\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.17833\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1387 - val_loss: 0.1834\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17833\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1405 - val_loss: 0.1802\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17833\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1402 - val_loss: 0.1785\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17833\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1275 - val_loss: 0.1713\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.17833 to 0.17126, saving model to folds6.hdf5\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1223 - val_loss: 0.1717\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17126\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1216 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.17126\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1205 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17126\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1203 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17126\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1193 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17126\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1191 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17126\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1177 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17126\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1182 - val_loss: 0.1719\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17126\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1178 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17126\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1165 - val_loss: 0.1717\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17126\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1138 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.17126 to 0.16950, saving model to folds6.hdf5\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1110 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.16950\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1103 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.16950\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1098 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.16950\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1091 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.16950\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1084 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.16950\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1085 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.16950\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1081 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.16950\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1079 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.16950\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1075 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.16950\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1070 - val_loss: 0.1713\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.16950\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1052 - val_loss: 0.1696\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.16950\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1034 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.16950\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1034 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.16950\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1029 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16950\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1024 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16950\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1021 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16950\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1021 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16950\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1012 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16950\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1015 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16950\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1011 - val_loss: 0.1712\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16950\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1005 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16950\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0996 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16950\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0994 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16950\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0988 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16950\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0989 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16950\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0987 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16950\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0985 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16950\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0984 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16950\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0984 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16950\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0980 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16950\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0974 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16950\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0972 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16950\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0972 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16950\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0969 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16950\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0969 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16950\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0971 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16950\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0969 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16950\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0964 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16950\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0967 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16950\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0969 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16950\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0959 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16950\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0959 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16950\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0959 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16950\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0960 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16950\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0959 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16950\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0960 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16950\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 10s 154ms/step - loss: 0.0962 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16950\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0957 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16950\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0957 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16950\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0957 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16950\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0957 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16950\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0955 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16950\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0955 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16950\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0953 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16950\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.0957 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16950\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.0956 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16950\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0951 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16950\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0956 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16950\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0959 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16950\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0953 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16950\n",
      "Epoch 00158: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 8 < ---------------\n",
      "Epoch 1/300\n",
      "67/67 [==============================] - 57s 434ms/step - loss: 4.0696 - val_loss: 1.2962\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29619, saving model to folds7.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 1.0301 - val_loss: 0.7775\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.29619 to 0.77754, saving model to folds7.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.6924 - val_loss: 0.7424\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77754 to 0.74241, saving model to folds7.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.6208 - val_loss: 0.5544\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74241 to 0.55436, saving model to folds7.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.5303 - val_loss: 0.5193\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55436 to 0.51931, saving model to folds7.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.4737 - val_loss: 0.4388\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51931 to 0.43878, saving model to folds7.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4463 - val_loss: 0.4631\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.43878\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.4343 - val_loss: 0.4437\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.43878\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.4084 - val_loss: 0.3806\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43878 to 0.38058, saving model to folds7.hdf5\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.3793 - val_loss: 0.4042\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38058\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.3916 - val_loss: 0.3705\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.38058 to 0.37053, saving model to folds7.hdf5\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3569 - val_loss: 0.3422\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.37053 to 0.34220, saving model to folds7.hdf5\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3485 - val_loss: 0.3314\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34220 to 0.33137, saving model to folds7.hdf5\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3277 - val_loss: 0.3579\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.33137\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3362 - val_loss: 0.3647\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.33137\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.3311 - val_loss: 0.3211\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33137 to 0.32109, saving model to folds7.hdf5\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3105 - val_loss: 0.3452\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32109\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3055 - val_loss: 0.3630\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32109\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3207 - val_loss: 0.3253\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.32109\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3040 - val_loss: 0.3159\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.32109 to 0.31591, saving model to folds7.hdf5\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2969 - val_loss: 0.2801\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.31591 to 0.28012, saving model to folds7.hdf5\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2832 - val_loss: 0.3156\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.28012\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2980 - val_loss: 0.3201\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28012\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 0.2730 - val_loss: 0.2720\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.28012 to 0.27200, saving model to folds7.hdf5\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2646 - val_loss: 0.3051\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27200\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2767 - val_loss: 0.2741\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.27200\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2596 - val_loss: 0.2543\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.27200 to 0.25430, saving model to folds7.hdf5\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2535 - val_loss: 0.2607\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.25430\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2477 - val_loss: 0.3124\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.25430\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2959 - val_loss: 0.2536\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.25430 to 0.25362, saving model to folds7.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2520 - val_loss: 0.2440\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.25362 to 0.24398, saving model to folds7.hdf5\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2420 - val_loss: 0.2434\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.24398 to 0.24336, saving model to folds7.hdf5\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2330 - val_loss: 0.3234\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24336\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2843 - val_loss: 0.2455\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24336\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2329 - val_loss: 0.2361\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.24336 to 0.23610, saving model to folds7.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2288 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.23610 to 0.22679, saving model to folds7.hdf5\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2229 - val_loss: 0.2529\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.22679\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2295 - val_loss: 0.2478\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.22679\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2251 - val_loss: 0.2688\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.22679\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2314 - val_loss: 0.2325\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.22679\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.2220 - val_loss: 0.2286\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.22679\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2214 - val_loss: 0.2323\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.22679\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2383 - val_loss: 0.2374\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.22679\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2209 - val_loss: 0.2504\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22679\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2272 - val_loss: 0.2215\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.22679 to 0.22155, saving model to folds7.hdf5\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2135 - val_loss: 0.2406\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.22155\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2119 - val_loss: 0.2220\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.22155\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2071 - val_loss: 0.2141\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.22155 to 0.21414, saving model to folds7.hdf5\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2136 - val_loss: 0.2115\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.21414 to 0.21152, saving model to folds7.hdf5\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2015 - val_loss: 0.2219\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21152\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2038 - val_loss: 0.2377\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21152\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2054 - val_loss: 0.2037\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.21152 to 0.20369, saving model to folds7.hdf5\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1945 - val_loss: 0.2018\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.20369 to 0.20181, saving model to folds7.hdf5\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1904 - val_loss: 0.2123\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.20181\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1998 - val_loss: 0.2117\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20181\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1983 - val_loss: 0.2291\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.20181\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2395 - val_loss: 0.2251\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20181\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2113 - val_loss: 0.2444\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20181\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2110 - val_loss: 0.2152\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20181\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2029 - val_loss: 0.2212\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20181\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1957 - val_loss: 0.2117\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20181\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1928 - val_loss: 0.2107\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20181\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1887 - val_loss: 0.2399\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20181\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1908 - val_loss: 0.1849\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.20181 to 0.18494, saving model to folds7.hdf5\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1642 - val_loss: 0.1821\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.18494 to 0.18214, saving model to folds7.hdf5\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1586 - val_loss: 0.1824\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.18214\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1573 - val_loss: 0.1811\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.18214 to 0.18106, saving model to folds7.hdf5\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1535 - val_loss: 0.1833\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18106\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1552 - val_loss: 0.1805\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.18106 to 0.18045, saving model to folds7.hdf5\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1536 - val_loss: 0.1820\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18045\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1547 - val_loss: 0.1811\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.18045\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1532 - val_loss: 0.1792\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.18045 to 0.17920, saving model to folds7.hdf5\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1507 - val_loss: 0.1788\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.17920 to 0.17885, saving model to folds7.hdf5\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1497 - val_loss: 0.1753\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.17885 to 0.17530, saving model to folds7.hdf5\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.1463 - val_loss: 0.1759\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.17530\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1457 - val_loss: 0.1801\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.17530\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1522 - val_loss: 0.1772\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17530\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1458 - val_loss: 0.1744\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.17530 to 0.17435, saving model to folds7.hdf5\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1452 - val_loss: 0.1749\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17435\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1459 - val_loss: 0.1774\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17435\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1488 - val_loss: 0.1754\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17435\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1450 - val_loss: 0.1799\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.17435\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1488 - val_loss: 0.1774\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.17435\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1447 - val_loss: 0.1847\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17435\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1494 - val_loss: 0.1757\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17435\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1408 - val_loss: 0.1803\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17435\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1434 - val_loss: 0.1797\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17435\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1442 - val_loss: 0.1793\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17435\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1365 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.17435 to 0.16929, saving model to folds7.hdf5\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1275 - val_loss: 0.1681\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.16929 to 0.16807, saving model to folds7.hdf5\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1252 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.16807 to 0.16767, saving model to folds7.hdf5\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1244 - val_loss: 0.1692\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.16767\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1239 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.16767\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1229 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.16767\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1214 - val_loss: 0.1689\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.16767\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1214 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.16767\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1206 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.16767 to 0.16664, saving model to folds7.hdf5\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1200 - val_loss: 0.1667\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.16664\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1200 - val_loss: 0.1670\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.16664\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1196 - val_loss: 0.1686\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.16664\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1193 - val_loss: 0.1694\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.16664\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 11s 157ms/step - loss: 0.1190 - val_loss: 0.1685\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.16664\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1184 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.16664\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1195 - val_loss: 0.1688\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.16664\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1175 - val_loss: 0.1682\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.16664\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1168 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.16664\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1165 - val_loss: 0.1671\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.16664\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1129 - val_loss: 0.1672\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.16664\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1086 - val_loss: 0.1658\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.16664 to 0.16578, saving model to folds7.hdf5\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1082 - val_loss: 0.1650\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.16578 to 0.16503, saving model to folds7.hdf5\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1080 - val_loss: 0.1656\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.16503\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1073 - val_loss: 0.1657\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16503\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1071 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16503\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1069 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.16503\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1065 - val_loss: 0.1659\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16503\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1061 - val_loss: 0.1675\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16503\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1059 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16503\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1055 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16503\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1049 - val_loss: 0.1667\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16503\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1051 - val_loss: 0.1673\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16503\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1032 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16503\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1013 - val_loss: 0.1655\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16503\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1008 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16503\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1004 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16503\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1000 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16503\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0994 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16503\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0993 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16503\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0987 - val_loss: 0.1669\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16503\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0989 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16503\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0986 - val_loss: 0.1657\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16503\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0979 - val_loss: 0.1656\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16503\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0969 - val_loss: 0.1657\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16503\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.0970 - val_loss: 0.1660\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16503\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0966 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16503\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0970 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16503\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0964 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16503\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0962 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16503\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0962 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16503\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0956 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16503\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0959 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16503\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0953 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16503\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0951 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16503\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0949 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16503\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0950 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16503\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0950 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16503\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0945 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16503\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0949 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16503\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0943 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16503\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0945 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16503\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0941 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16503\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0941 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16503\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0941 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16503\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0939 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16503\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0940 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16503\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0938 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16503\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0938 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16503\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0941 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16503\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0938 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16503\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0936 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16503\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0934 - val_loss: 0.1662\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16503\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0936 - val_loss: 0.1663\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16503\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0932 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16503\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0934 - val_loss: 0.1664\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16503\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0938 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16503\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0939 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16503\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.0931 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16503\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0936 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16503\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0936 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16503\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0929 - val_loss: 0.1666\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16503\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0933 - val_loss: 0.1665\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16503\n",
      "Epoch 00170: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 9 < ---------------\n",
      "Epoch 1/300\n",
      "67/67 [==============================] - 56s 442ms/step - loss: 3.9965 - val_loss: 1.2372\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.23719, saving model to folds8.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 1.0936 - val_loss: 0.8565\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.23719 to 0.85650, saving model to folds8.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.7291 - val_loss: 0.6731\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.85650 to 0.67312, saving model to folds8.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.6128 - val_loss: 0.5666\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.67312 to 0.56663, saving model to folds8.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.5641 - val_loss: 0.5954\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56663\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.4977 - val_loss: 0.4788\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56663 to 0.47877, saving model to folds8.hdf5\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.4554 - val_loss: 0.5304\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47877\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 0.4356 - val_loss: 0.4563\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47877 to 0.45625, saving model to folds8.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.4261 - val_loss: 0.4629\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.45625\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3875 - val_loss: 0.3754\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45625 to 0.37541, saving model to folds8.hdf5\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3927 - val_loss: 0.3770\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.37541\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3641 - val_loss: 0.3501\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.37541 to 0.35008, saving model to folds8.hdf5\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.3502 - val_loss: 0.3656\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.35008\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3599 - val_loss: 0.3445\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.35008 to 0.34449, saving model to folds8.hdf5\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3487 - val_loss: 0.3392\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.34449 to 0.33922, saving model to folds8.hdf5\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3351 - val_loss: 0.3230\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.33922 to 0.32304, saving model to folds8.hdf5\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3217 - val_loss: 0.3248\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32304\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3104 - val_loss: 0.3381\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32304\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3187 - val_loss: 0.3233\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.32304\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3185 - val_loss: 0.2958\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.32304 to 0.29577, saving model to folds8.hdf5\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2899 - val_loss: 0.2968\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29577\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2936 - val_loss: 0.2981\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.29577\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2868 - val_loss: 0.2865\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.29577 to 0.28646, saving model to folds8.hdf5\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2789 - val_loss: 0.3090\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.28646\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2898 - val_loss: 0.2666\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.28646 to 0.26661, saving model to folds8.hdf5\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2644 - val_loss: 0.2778\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.26661\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2733 - val_loss: 0.2808\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.26661\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.2574 - val_loss: 0.2651\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.26661 to 0.26510, saving model to folds8.hdf5\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.2554 - val_loss: 0.2743\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.26510\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2524 - val_loss: 0.2787\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.26510\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2731 - val_loss: 0.2614\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.26510 to 0.26141, saving model to folds8.hdf5\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2551 - val_loss: 0.3127\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.26141\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2613 - val_loss: 0.2573\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.26141 to 0.25726, saving model to folds8.hdf5\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2468 - val_loss: 0.2618\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.25726\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2457 - val_loss: 0.2447\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.25726 to 0.24469, saving model to folds8.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2395 - val_loss: 0.2448\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24469\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2320 - val_loss: 0.2514\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.24469\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2306 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24469\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2300 - val_loss: 0.2376\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.24469 to 0.23765, saving model to folds8.hdf5\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2213 - val_loss: 0.2318\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.23765 to 0.23178, saving model to folds8.hdf5\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2237 - val_loss: 0.2382\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.23178\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2223 - val_loss: 0.2314\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.23178 to 0.23137, saving model to folds8.hdf5\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2222 - val_loss: 0.2536\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.23137\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2428 - val_loss: 0.2537\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.23137\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.2265 - val_loss: 0.2432\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.23137\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2218 - val_loss: 0.2337\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.23137\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2171 - val_loss: 0.2287\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.23137 to 0.22874, saving model to folds8.hdf5\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2133 - val_loss: 0.2420\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.22874\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2109 - val_loss: 0.2336\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.22874\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2153 - val_loss: 0.2268\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.22874 to 0.22681, saving model to folds8.hdf5\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.2208 - val_loss: 0.2510\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.22681\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2339 - val_loss: 0.2519\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.22681\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2267 - val_loss: 0.2452\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.22681\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2123 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.22681 to 0.21757, saving model to folds8.hdf5\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2050 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21757\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2148 - val_loss: 0.2218\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.21757\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2035 - val_loss: 0.2188\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.21757\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1956 - val_loss: 0.2101\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.21757 to 0.21006, saving model to folds8.hdf5\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1945 - val_loss: 0.2148\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.21006\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1924 - val_loss: 0.2358\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.21006\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2006 - val_loss: 0.2087\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.21006 to 0.20867, saving model to folds8.hdf5\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1909 - val_loss: 0.2139\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20867\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1896 - val_loss: 0.2271\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20867\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1889 - val_loss: 0.2093\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20867\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1892 - val_loss: 0.2231\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20867\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1906 - val_loss: 0.2101\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20867\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1870 - val_loss: 0.2147\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.20867\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1917 - val_loss: 0.2612\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.20867\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2003 - val_loss: 0.2176\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.20867\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1873 - val_loss: 0.2074\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.20867 to 0.20739, saving model to folds8.hdf5\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1801 - val_loss: 0.2077\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.20739\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1834 - val_loss: 0.2118\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.20739\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1836 - val_loss: 0.2125\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.20739\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1998 - val_loss: 0.2274\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.20739\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1944 - val_loss: 0.2260\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.20739\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1906 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.20739\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1842 - val_loss: 0.2092\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.20739\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1942 - val_loss: 0.2206\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.20739\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1830 - val_loss: 0.2105\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.20739\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1792 - val_loss: 0.1991\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.20739 to 0.19909, saving model to folds8.hdf5\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1829 - val_loss: 0.2092\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.19909\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1845 - val_loss: 0.2126\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.19909\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1803 - val_loss: 0.2091\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.19909\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1785 - val_loss: 0.2026\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.19909\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1710 - val_loss: 0.2092\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.19909\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1793 - val_loss: 0.2052\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.19909\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1822 - val_loss: 0.2021\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.19909\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1722 - val_loss: 0.1984\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.19909 to 0.19844, saving model to folds8.hdf5\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1698 - val_loss: 0.1985\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.19844\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1709 - val_loss: 0.2001\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.19844\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1686 - val_loss: 0.2117\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.19844\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1680 - val_loss: 0.2066\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.19844\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1720 - val_loss: 0.1943\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.19844 to 0.19430, saving model to folds8.hdf5\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1605 - val_loss: 0.1973\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.19430\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1638 - val_loss: 0.1928\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.19430 to 0.19275, saving model to folds8.hdf5\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1794 - val_loss: 0.1940\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.19275\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1609 - val_loss: 0.2083\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.19275\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1651 - val_loss: 0.2327\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.19275\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2028 - val_loss: 0.2835\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.19275\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2416 - val_loss: 0.2310\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.19275\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1927 - val_loss: 0.2084\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.19275\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1856 - val_loss: 0.2086\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.19275\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1755 - val_loss: 0.2060\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.19275\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1687 - val_loss: 0.1912\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.19275 to 0.19125, saving model to folds8.hdf5\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1613 - val_loss: 0.1932\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.19125\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1609 - val_loss: 0.1983\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.19125\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1602 - val_loss: 0.1928\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.19125\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1575 - val_loss: 0.1892\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.19125 to 0.18917, saving model to folds8.hdf5\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1572 - val_loss: 0.1969\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.18917\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1523 - val_loss: 0.1973\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.18917\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 11s 158ms/step - loss: 0.1543 - val_loss: 0.1918\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.18917\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1521 - val_loss: 0.1817\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.18917 to 0.18173, saving model to folds8.hdf5\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1464 - val_loss: 0.1976\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.18173\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1475 - val_loss: 0.1896\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.18173\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1454 - val_loss: 0.1875\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.18173\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1436 - val_loss: 0.1948\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.18173\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1472 - val_loss: 0.1839\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.18173\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1458 - val_loss: 0.1831\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.18173\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1429 - val_loss: 0.1880\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.18173\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1460 - val_loss: 0.1837\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.18173\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1467 - val_loss: 0.1964\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.18173\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1446 - val_loss: 0.1957\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.18173\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1323 - val_loss: 0.1754\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.18173 to 0.17537, saving model to folds8.hdf5\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1211 - val_loss: 0.1751\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.17537 to 0.17507, saving model to folds8.hdf5\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1206 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.17507 to 0.17422, saving model to folds8.hdf5\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1186 - val_loss: 0.1747\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.17422\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1177 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.17422\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1163 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.17422 to 0.17316, saving model to folds8.hdf5\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1157 - val_loss: 0.1787\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.17316\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1158 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.17316\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.1149 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.17316\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1141 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.17316 to 0.17296, saving model to folds8.hdf5\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1140 - val_loss: 0.1765\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.17296\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1137 - val_loss: 0.1740\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.17296\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1148 - val_loss: 0.1755\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.17296\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1131 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.17296\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1128 - val_loss: 0.1790\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.17296\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1129 - val_loss: 0.1756\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.17296\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1122 - val_loss: 0.1746\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.17296\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1127 - val_loss: 0.1793\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.17296\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1107 - val_loss: 0.1779\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.17296\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1101 - val_loss: 0.1796\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.17296\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1076 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.17296 to 0.17282, saving model to folds8.hdf5\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0999 - val_loss: 0.1715\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.17282 to 0.17154, saving model to folds8.hdf5\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0978 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.17154 to 0.17082, saving model to folds8.hdf5\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0981 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.17082\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0973 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.17082\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0966 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.17082\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0964 - val_loss: 0.1715\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.17082\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0960 - val_loss: 0.1718\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.17082\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0954 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.17082\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0945 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.17082\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0951 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.17082\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0941 - val_loss: 0.1760\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.17082\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0946 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.17082\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0918 - val_loss: 0.1712\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.17082\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0887 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.17082\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0881 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.17082\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0882 - val_loss: 0.1722\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.17082\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0876 - val_loss: 0.1717\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.17082\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0871 - val_loss: 0.1725\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.17082\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0871 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.17082\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0871 - val_loss: 0.1718\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.17082\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0863 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.17082\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0858 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.17082\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0847 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.17082\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0839 - val_loss: 0.1724\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.17082\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0836 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.17082\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0827 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.17082\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0834 - val_loss: 0.1729\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.17082\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.0832 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.17082\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0824 - val_loss: 0.1729\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.17082\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0820 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.17082\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.0823 - val_loss: 0.1726\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.17082\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0821 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.17082\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.0812 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.17082\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0808 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.17082\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0806 - val_loss: 0.1728\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.17082\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0805 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.17082\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0806 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.17082\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0805 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.17082\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0802 - val_loss: 0.1731\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.17082\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0800 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.17082\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0797 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.17082\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0801 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.17082\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0798 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.17082\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0796 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.17082\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0796 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.17082\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0792 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.17082\n",
      "Epoch 190/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0793 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.17082\n",
      "Epoch 191/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0796 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.17082\n",
      "Epoch 192/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0791 - val_loss: 0.1732\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.17082\n",
      "Epoch 193/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0793 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.17082\n",
      "Epoch 194/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0788 - val_loss: 0.1738\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.17082\n",
      "Epoch 195/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0791 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.17082\n",
      "Epoch 196/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0788 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.17082\n",
      "Epoch 197/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0788 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.17082\n",
      "Epoch 198/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0783 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.17082\n",
      "Epoch 199/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0786 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.17082\n",
      "Epoch 200/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0783 - val_loss: 0.1734\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.17082\n",
      "Epoch 201/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0785 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.17082\n",
      "Epoch 202/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0785 - val_loss: 0.1735\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.17082\n",
      "Epoch 203/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0785 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.17082\n",
      "Epoch 204/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0783 - val_loss: 0.1736\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.17082\n",
      "Epoch 205/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0782 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00205: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.17082\n",
      "Epoch 00205: early stopping\n",
      "50/50 - 7s\n",
      "--------------- > Fold 10 < ---------------\n",
      "Epoch 1/300\n",
      "67/67 [==============================] - 58s 447ms/step - loss: 4.0508 - val_loss: 1.2693\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.26926, saving model to folds9.hdf5\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 1.0060 - val_loss: 0.7322\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.26926 to 0.73224, saving model to folds9.hdf5\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.6781 - val_loss: 0.5772\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73224 to 0.57715, saving model to folds9.hdf5\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.5891 - val_loss: 0.5249\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57715 to 0.52488, saving model to folds9.hdf5\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.5033 - val_loss: 0.5033\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52488 to 0.50332, saving model to folds9.hdf5\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.4714 - val_loss: 0.5501\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.50332\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.4552 - val_loss: 0.4501\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.50332 to 0.45007, saving model to folds9.hdf5\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 0.4291 - val_loss: 0.4133\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.45007 to 0.41326, saving model to folds9.hdf5\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.3999 - val_loss: 0.3713\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.41326 to 0.37129, saving model to folds9.hdf5\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3801 - val_loss: 0.3680\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37129 to 0.36804, saving model to folds9.hdf5\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3652 - val_loss: 0.3743\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36804\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3442 - val_loss: 0.3720\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.36804\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3419 - val_loss: 0.3777\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36804\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3427 - val_loss: 0.3119\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.36804 to 0.31192, saving model to folds9.hdf5\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.3027 - val_loss: 0.2982\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.31192 to 0.29825, saving model to folds9.hdf5\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3038 - val_loss: 0.3143\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.29825\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2986 - val_loss: 0.2919\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.29825 to 0.29191, saving model to folds9.hdf5\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2906 - val_loss: 0.2946\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29191\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.3005 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.29191\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2797 - val_loss: 0.2927\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.29191\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.2781 - val_loss: 0.2965\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29191\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2761 - val_loss: 0.2863\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29191 to 0.28629, saving model to folds9.hdf5\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 11s 160ms/step - loss: 0.2713 - val_loss: 0.3113\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.28629\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.2820 - val_loss: 0.2622\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.28629 to 0.26218, saving model to folds9.hdf5\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2529 - val_loss: 0.3315\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26218\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2712 - val_loss: 0.2616\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.26218 to 0.26156, saving model to folds9.hdf5\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2485 - val_loss: 0.2494\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.26156 to 0.24944, saving model to folds9.hdf5\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2433 - val_loss: 0.2573\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.24944\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2364 - val_loss: 0.2708\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.24944\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2433 - val_loss: 0.2440\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.24944 to 0.24401, saving model to folds9.hdf5\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2379 - val_loss: 0.2597\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.24401\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2414 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.24401\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2310 - val_loss: 0.2634\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24401\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2278 - val_loss: 0.2464\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24401\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2259 - val_loss: 0.2275\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.24401 to 0.22752, saving model to folds9.hdf5\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.2214 - val_loss: 0.2456\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.22752\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.2219 - val_loss: 0.2340\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.22752\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2184 - val_loss: 0.2505\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.22752\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2322 - val_loss: 0.2577\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.22752\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2227 - val_loss: 0.2469\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.22752\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2241 - val_loss: 0.2303\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.22752\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2139 - val_loss: 0.2257\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.22752 to 0.22574, saving model to folds9.hdf5\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2218 - val_loss: 0.2338\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.22574\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2124 - val_loss: 0.2425\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22574\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2232 - val_loss: 0.2581\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.22574\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2268 - val_loss: 0.2379\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.22574\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2096 - val_loss: 0.2347\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.22574\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2122 - val_loss: 0.2280\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.22574\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 0.2062 - val_loss: 0.2162\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.22574 to 0.21615, saving model to folds9.hdf5\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1960 - val_loss: 0.2422\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21615\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1982 - val_loss: 0.2313\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21615\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1928 - val_loss: 0.2122\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.21615 to 0.21224, saving model to folds9.hdf5\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1865 - val_loss: 0.2227\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21224\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1901 - val_loss: 0.2152\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.21224\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1881 - val_loss: 0.2185\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.21224\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2036 - val_loss: 0.2060\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.21224 to 0.20599, saving model to folds9.hdf5\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1818 - val_loss: 0.2178\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20599\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1965 - val_loss: 0.2309\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20599\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.2243 - val_loss: 0.2475\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.20599\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.2174 - val_loss: 0.2193\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.20599\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1966 - val_loss: 0.2174\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.20599\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1975 - val_loss: 0.2072\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.20599\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1887 - val_loss: 0.2207\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.20599\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1898 - val_loss: 0.2110\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.20599\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1916 - val_loss: 0.2082\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.20599\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1824 - val_loss: 0.2115\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.20599\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1695 - val_loss: 0.1858\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.20599 to 0.18578, saving model to folds9.hdf5\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1530 - val_loss: 0.1872\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.18578\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1501 - val_loss: 0.1827\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.18578 to 0.18272, saving model to folds9.hdf5\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1489 - val_loss: 0.1868\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18272\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1494 - val_loss: 0.1813\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.18272 to 0.18130, saving model to folds9.hdf5\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1434 - val_loss: 0.1817\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.18130\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1445 - val_loss: 0.1783\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.18130 to 0.17832, saving model to folds9.hdf5\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1446 - val_loss: 0.1787\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.17832\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1442 - val_loss: 0.1844\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.17832\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1515 - val_loss: 0.1940\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.17832\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1469 - val_loss: 0.1827\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17832\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1419 - val_loss: 0.1813\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.17832\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1417 - val_loss: 0.1874\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17832\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1432 - val_loss: 0.1805\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17832\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1431 - val_loss: 0.1827\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17832\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1403 - val_loss: 0.1778\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.17832 to 0.17777, saving model to folds9.hdf5\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1390 - val_loss: 0.1766\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.17777 to 0.17664, saving model to folds9.hdf5\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1393 - val_loss: 0.1803\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17664\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.1408 - val_loss: 0.1823\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17664\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1409 - val_loss: 0.1849\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17664\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1387 - val_loss: 0.1829\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17664\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1397 - val_loss: 0.1815\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17664\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1384 - val_loss: 0.1861\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.17664\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1446 - val_loss: 0.1977\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17664\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1500 - val_loss: 0.1807\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17664\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1425 - val_loss: 0.1841\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17664\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1409 - val_loss: 0.1884\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17664\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1302 - val_loss: 0.1727\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.17664 to 0.17271, saving model to folds9.hdf5\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1203 - val_loss: 0.1725\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.17271 to 0.17249, saving model to folds9.hdf5\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1199 - val_loss: 0.1768\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17249\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1204 - val_loss: 0.1742\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17249\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1196 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.17249 to 0.17197, saving model to folds9.hdf5\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1171 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17197\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 10s 152ms/step - loss: 0.1166 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17197\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1152 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.17197 to 0.17070, saving model to folds9.hdf5\n",
      "Epoch 102/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1151 - val_loss: 0.1720\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.17070\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.1173 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.17070 to 0.17052, saving model to folds9.hdf5\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1141 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.17052\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1138 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.17052\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1133 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.17052 to 0.17018, saving model to folds9.hdf5\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.1118 - val_loss: 0.1741\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.17018\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1125 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.17018\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1123 - val_loss: 0.1724\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.17018\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1117 - val_loss: 0.1717\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.17018\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1113 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.17018\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.1099 - val_loss: 0.1733\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.17018\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.1121 - val_loss: 0.1716\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.17018\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1080 - val_loss: 0.1730\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.17018\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1094 - val_loss: 0.1767\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.17018\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1089 - val_loss: 0.1713\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.17018\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1038 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.17018\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1004 - val_loss: 0.1691\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.17018 to 0.16915, saving model to folds9.hdf5\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.1000 - val_loss: 0.1694\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16915\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0990 - val_loss: 0.1695\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16915\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0988 - val_loss: 0.1699\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16915\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0987 - val_loss: 0.1712\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16915\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0985 - val_loss: 0.1694\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16915\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0977 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16915\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0973 - val_loss: 0.1688\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.16915 to 0.16884, saving model to folds9.hdf5\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0980 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16884\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0974 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16884\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0970 - val_loss: 0.1729\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16884\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0972 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16884\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0961 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16884\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0959 - val_loss: 0.1714\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16884\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0962 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16884\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0951 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16884\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0953 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16884\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0947 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16884\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0927 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16884\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0904 - val_loss: 0.1700\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16884\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0903 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.16884\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 0.0900 - val_loss: 0.1701\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16884\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0898 - val_loss: 0.1697\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16884\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0899 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16884\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0894 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16884\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 0.0895 - val_loss: 0.1702\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16884\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0888 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16884\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0886 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16884\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0870 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16884\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 0.0871 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16884\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0870 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16884\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0866 - val_loss: 0.1705\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16884\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0862 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.16884\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0866 - val_loss: 0.1703\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16884\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0861 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16884\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0867 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16884\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0857 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16884\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0857 - val_loss: 0.1706\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16884\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0856 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16884\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0853 - val_loss: 0.1704\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16884\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0853 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16884\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0853 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16884\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0849 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16884\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0849 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16884\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0846 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16884\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0850 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16884\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0851 - val_loss: 0.1707\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16884\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0845 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00165: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16884\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0844 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16884\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0847 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16884\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0841 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16884\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0840 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16884\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0841 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16884\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0841 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16884\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0843 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16884\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0839 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16884\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0838 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16884\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 9s 141ms/step - loss: 0.0840 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16884\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0840 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16884\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0833 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16884\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0836 - val_loss: 0.1709\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16884\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0836 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16884\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0834 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16884\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0837 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16884\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0834 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16884\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 9s 142ms/step - loss: 0.0836 - val_loss: 0.1710\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16884\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.0833 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16884\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 10s 142ms/step - loss: 0.0837 - val_loss: 0.1711\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16884\n",
      "Epoch 00185: early stopping\n",
      "50/50 - 8s\n"
     ]
    }
   ],
   "source": [
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "with tpu_strategy.scope():\n",
    "    \n",
    "    K = keras.backend\n",
    "\n",
    "    def create_model():\n",
    "        inputs = keras.layers.Input(shape=train.shape[-2:])\n",
    "        x = inputs\n",
    "        for units in [1024, 512, 256, 128]:\n",
    "            x = keras.layers.Bidirectional(keras.layers.LSTM(units, return_sequences=True))(x)\n",
    "        x = keras.layers.Dense(128, activation='selu')(x)\n",
    "        outputs = keras.layers.Dense(1)(x)\n",
    "        outputs = ScaleLayer()(outputs)\n",
    "        \n",
    "        model  = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        model.compile(optimizer=\"adam\", loss='mae') \n",
    "        return model\n",
    "    \n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=1970)\n",
    "    test_preds = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "        \n",
    "        model = create_model()\n",
    "\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, \n",
    "                           mode=\"min\", restore_best_weights=True)\n",
    "    \n",
    "        checkpoint_filepath = f\"folds{fold}.hdf5\"\n",
    "        sv = keras.callbacks.ModelCheckpoint(\n",
    "            checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "            save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "            options=None\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n",
    "                  epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
    "        \n",
    "        test_preds.append(model.predict(test, batch_size=BATCH_SIZE, verbose=2)\n",
    "                          .squeeze().reshape(-1, 1).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e879c7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T03:20:38.402605Z",
     "iopub.status.busy": "2021-10-05T03:20:38.401924Z",
     "iopub.status.idle": "2021-10-05T03:20:51.288483Z",
     "shell.execute_reply": "2021-10-05T03:20:51.287860Z"
    },
    "papermill": {
     "duration": 52.746502,
     "end_time": "2021-10-05T03:20:51.288653",
     "exception": false,
     "start_time": "2021-10-05T03:19:58.542151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = np.median(np.vstack(test_preds), axis=0)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1fd68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T03:22:11.712658Z",
     "iopub.status.busy": "2021-10-05T03:22:11.711819Z",
     "iopub.status.idle": "2021-10-05T03:22:11.715191Z",
     "shell.execute_reply": "2021-10-05T03:22:11.715700Z"
    },
    "papermill": {
     "duration": 40.571181,
     "end_time": "2021-10-05T03:22:11.715875",
     "exception": false,
     "start_time": "2021-10-05T03:21:31.144694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.259304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.907794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.173232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.595045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.141692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  pressure\n",
       "0   1  6.259304\n",
       "1   2  5.907794\n",
       "2   3  7.173232\n",
       "3   4  7.595045\n",
       "4   5  9.141692"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19370.617875,
   "end_time": "2021-10-05T03:22:54.764023",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-04T22:00:04.146148",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
